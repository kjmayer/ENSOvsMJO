{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9a6521f-0052-4657-8336-00fb21e8409a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Calculate Interpretability Data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be49fae-2aa3-4bf9-9d4c-f12d003662ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prep for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b66c4fa-5299-467a-809d-cb3fc8d30589",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 09:19:45.247372: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-16 09:19:46.963968: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random \n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "import sys\n",
    "sys.path.append('/glade/work/kjmayer/research/catalyst/ENSOvsMJO/utils/')\n",
    "# sys.path.append('/glade/u/home/wchapman/ENSOvsMJO/utils/')\n",
    "from exp_hp import get_hp\n",
    "from trainGordon_utils import subset, build_model, fullmodel, scheduler, plot_results, adjust_spines\n",
    "from dataprep_utils import get_testing\n",
    "sys.path.append('/glade/work/kjmayer/research/catalyst/ENSOvsMJO/interpret/')\n",
    "# sys.path.append('/glade/u/home/wchapman/ENSOvsMJO/interpret/')\n",
    "from Gordon_interp import getoutputvecs, confvacc, iconfcorr\n",
    "\n",
    "\n",
    "# import importlib\n",
    "# importlib.reload(sys.modules[\"Gordon_interp\"])\n",
    "# from Gordon_interp import getoutputvecs, confvacc, iconfcorr\n",
    "# importlib.reload(sys.modules[\"trainGordon_utils\"])\n",
    "# from trainGordon_utils import subset, build_model, fullmodel, scheduler, plot_results\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('text',usetex=True)\n",
    "plt.rcParams['font.family']='sans-serif'\n",
    "plt.rcParams['font.sans-serif']=['Verdana']\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "def adjust_spines(ax, spines):\n",
    "    for loc, spine in ax.spines.items():\n",
    "        if loc in spines:\n",
    "            spine.set_position(('outward', 5))\n",
    "        else:\n",
    "            spine.set_color('none')\n",
    "    if 'left' in spines:\n",
    "        ax.yaxis.set_ticks_position('left')\n",
    "    else:\n",
    "        ax.yaxis.set_ticks([])\n",
    "    if 'bottom' in spines:\n",
    "        ax.xaxis.set_ticks_position('bottom')\n",
    "    else:\n",
    "            ax.xaxis.set_ticks([])\n",
    "mpl.rcParams['figure.facecolor'] = 'white'\n",
    "mpl.rcParams['figure.dpi'] = 150\n",
    "dpiFig = 300."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb4fdd3-934d-4eea-b75f-64c18a60aa25",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09f14733-e325-454d-9f75-245f84158ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = '/glade/work/kjmayer/research/catalyst/ENSOvsMJO/data/models/'\n",
    "# MODEL_DIR = '/glade/scratch/wchapman/ENSOmjo_ML_models/saved_models/'\n",
    "EXP_NAME = 'default'\n",
    "hps = get_hp(EXP_NAME)\n",
    "# variables:\n",
    "DROPOUT_RATE = hps['DROPOUT_RATE']\n",
    "\n",
    "MODELNAME1 = 'ENSO'\n",
    "RIDGE1 = hps['RIDGE1']\n",
    "HIDDENS1 = hps['HIDDENS1']\n",
    "\n",
    "MODELNAME2 = 'MJO'\n",
    "RIDGE2 = hps['RIDGE2']\n",
    "HIDDENS2 = hps['HIDDENS2']\n",
    "\n",
    "BATCH_SIZE = hps['BATCH_SIZE']\n",
    "N_EPOCHS = 10000\n",
    "PATIENCE = hps['PATIENCE'] # number of epochs of no \"improvement\" before training is stopped\n",
    "LR = hps['LR'] # learning rate\n",
    "\n",
    "\n",
    "LEADS = np.arange(7,31)\n",
    "AVGS = np.arange(2,32)\n",
    "SEEDS = np.arange(1,6)\n",
    "\n",
    "SAVE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee26ef1-260f-4051-ac54-78fe2b4e3ddd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Analyze Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b67d57a-6ef7-4f39-9744-744f90117497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEAD: 7\n",
      "AVG: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-14 12:45:12.785280: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 2s 2ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 1ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 1ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 2ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 1ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 1ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 2ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 1ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 1ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 2ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 1ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 1ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 2ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 1ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# model raw predictions\n",
    "# confidence vs accuracy\n",
    "# model contribution fractions\n",
    "\n",
    "for l in LEADS[:1]:\n",
    "    for a in AVGS[:1]:\n",
    "        print('LEAD: '+str(l)+'\\nAVG: '+str(a))\n",
    "        \n",
    "        #check if files already exist:\n",
    "        ddir_save = '/glade/scratch/kjmayer/DATA/ENSOvsMJO/data/'\n",
    "        finame_confvsacc = 'confvsacc_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "        if not os.path.isfile(ddir_save+finame_confvsacc):\n",
    "            # print('load testing data')\n",
    "            X1test, X2test, Ytest = get_testing(N_z500runmean=a,\n",
    "                                                LEAD=l)\n",
    "\n",
    "            INPUT_SHAPE1 = np.shape(X1test)[1:][0]\n",
    "            INPUT_SHAPE2 = np.shape(X2test)[1:][0]\n",
    "\n",
    "            confvsacc = np.zeros(shape=(len(SEEDS),100))\n",
    "\n",
    "            model1_rawpreds = np.zeros(shape=(len(SEEDS),np.shape(X1test)[0],2))\n",
    "            model2_rawpreds = np.zeros(shape=(len(SEEDS),np.shape(X1test)[0],2))\n",
    "            model_rawpreds = np.zeros(shape=(len(SEEDS),np.shape(X1test)[0],2))\n",
    "            \n",
    "            model1_all_fracpred = np.zeros(shape=(len(SEEDS)))\n",
    "            model2_all_fracpred = np.zeros(shape=(len(SEEDS)))\n",
    "            model12_all_fracpred = np.zeros(shape=(len(SEEDS)))\n",
    "            \n",
    "            model1_allcorr_fracpred = np.zeros(shape=(len(SEEDS)))\n",
    "            model2_allcorr_fracpred = np.zeros(shape=(len(SEEDS)))\n",
    "            model12_allcorr_fracpred = np.zeros(shape=(len(SEEDS)))\n",
    "            \n",
    "            model1_conf_fracpred = np.zeros(shape=(len(SEEDS)))\n",
    "            model2_conf_fracpred = np.zeros(shape=(len(SEEDS)))\n",
    "            model12_conf_fracpred = np.zeros(shape=(len(SEEDS)))\n",
    "            \n",
    "            model1_confcorr_fracpred = np.zeros(shape=(len(SEEDS)))\n",
    "            model2_confcorr_fracpred = np.zeros(shape=(len(SEEDS)))\n",
    "            model12_confcorr_fracpred = np.zeros(shape=(len(SEEDS)))\n",
    "            \n",
    "            \n",
    "            for s in SEEDS:\n",
    "                # ENSO MODEL\n",
    "                model1, input1 = build_model(s,\n",
    "                                             DROPOUT_RATE,\n",
    "                                             RIDGE1,\n",
    "                                             HIDDENS1,\n",
    "                                             INPUT_SHAPE1,\n",
    "                                             MODELNAME1)\n",
    "                # MJO MODEL\n",
    "                model2, input2 = build_model(s,\n",
    "                                             DROPOUT_RATE,\n",
    "                                             RIDGE2,\n",
    "                                             HIDDENS2,\n",
    "                                             INPUT_SHAPE2,\n",
    "                                             MODELNAME2)   \n",
    "                # COMBINE ENSO & MJO MODEL\n",
    "                model = fullmodel(model1, model2,\n",
    "                                  input1, input2,\n",
    "                                  s)\n",
    "\n",
    "                MODEL_FINAME = 'LEAD_'+str(l)+'_AVG_'+str(a)+'__0000'+str(s)+'.h5'\n",
    "                model.load_weights(MODEL_DIR+MODEL_FINAME)\n",
    "\n",
    "                model_rawpreds[s-1] = model.predict((X1test,X2test))                \n",
    "                \n",
    "                conf    = np.max(model_rawpreds[s-1],axis=-1)\n",
    "                predval = np.argmax(model_rawpreds[s-1],axis=-1)\n",
    "                \n",
    "                # ------- confident predictions --------------------------------------------------------\n",
    "                per = 80\n",
    "                conf_thresh = np.percentile(conf,q=per)\n",
    "                # -------- confident [i_conf_predval] --------\n",
    "                i_conf_predval = np.where(conf > conf_thresh)[0]\n",
    "                \n",
    "                \n",
    "                # ----- confidence vs accuracy for all seeds: -------------------------------------------\n",
    "                confvsacc[s-1], _, _ = confvacc(confval = conf,\n",
    "                                              predval = predval,\n",
    "                                              Ytest   = Ytest)\n",
    "\n",
    "                # ----- model contribution: ------------------------------------------------------------\n",
    "                model1_rawpreds[s-1], model2_rawpreds[s-1] = getoutputvecs(model,\n",
    "                                                                       model1,\n",
    "                                                                       model2,\n",
    "                                                                       X1test,\n",
    "                                                                       X2test)\n",
    "                # model X winning class (model X output * weight)\n",
    "                model1pred = np.argmax(model1_rawpreds[s-1],axis=1)\n",
    "                model2pred = np.argmax(model2_rawpreds[s-1],axis=1)\n",
    "\n",
    "                # --------------------------------------------------------------------------------------\n",
    "                # ---------- all predictions contribution: ---------------------------------------------\n",
    "                # --------------------------------------------------------------------------------------\n",
    "                i_model1_samefinalpred = model1pred==predval\n",
    "                i_model2_samefinalpred = model2pred==predval\n",
    "                \n",
    "                # terminology: \"win\" = modelX prediction is also full model prediction\n",
    "                # model X same as final prediction & model ~X does not have that prediction\n",
    "                i_model1win = i_model1_samefinalpred & ~i_model2_samefinalpred\n",
    "                i_model2win = i_model2_samefinalpred & ~i_model1_samefinalpred\n",
    "                # model 1&2 have same final prediction\n",
    "                i_model12win = i_model1_samefinalpred & i_model2_samefinalpred\n",
    "                \n",
    "                # number of predictions of model(X) predicted class that is also full model prediction\n",
    "                n_model1win_predval = model1pred[i_model1win].shape[0]\n",
    "                n_model2win_predval = model2pred[i_model2win].shape[0]\n",
    "                n_model12win_predval = predval[i_model12win].shape[0]\n",
    "                \n",
    "                # these shapes should be equal (True), assuming ~i_model1corr & ~i_model2corr & i_modelcorr doesnt happen\n",
    "                if predval.shape[0] == n_model1win_predval + n_model2win_predval + n_model12win_predval:\n",
    "                    # print('SEED: '+str(s))\n",
    "                    # Percentage of model predictions correct due to just ENSO/MJO/ENSO&MJO:\n",
    "                    model1_all_fracpred[s-1]  = (n_model1win_predval/predval.shape[0])\n",
    "                    model2_all_fracpred[s-1]  = (n_model2win_predval/predval.shape[0])\n",
    "                    model12_all_fracpred[s-1] = (n_model12win_predval/predval.shape[0])\n",
    "                \n",
    "                \n",
    "                \n",
    "                # --------------------------------------------------------------------------------------\n",
    "                #  ---------- all correct predictions contribution:  -----------------------------------\n",
    "                # --------------------------------------------------------------------------------------\n",
    "                # Where ENSO/MJO/final model (model 1/model 2/total) are correct:\n",
    "                i_model1corr = model1pred==Ytest\n",
    "                i_model2corr = model2pred==Ytest\n",
    "                i_modelcorr  = predval==Ytest\n",
    "\n",
    "                # terminology: \"win\" = modelX prediction is also (correct) full model prediction\n",
    "                # model X correct & model correct (model ~X not correct)\n",
    "                i_model1win = i_model1corr & i_modelcorr & ~i_model2corr\n",
    "                i_model2win = i_model2corr & i_modelcorr & ~i_model1corr\n",
    "                # model 1&2 correct & model correct\n",
    "                i_model12win = i_model1corr & i_model2corr & i_modelcorr\n",
    "\n",
    "                # For correct predictions: model(X) values & predicted class when also full model prediction\n",
    "                model1win_contribution = model1_rawpreds[s-1][i_model1win]\n",
    "                model1win_predval = model1pred[i_model1win]\n",
    "\n",
    "                model2win_contribution = model2_rawpreds[s-1][i_model2win]\n",
    "                model2win_predval = model2pred[i_model2win]\n",
    "\n",
    "                model12win_predval = model_rawpreds[s-1][i_model12win]\n",
    "\n",
    "                # these shapes should be equal (True), assuming ~i_model1corr & ~i_model2corr & i_modelcorr doesnt happen\n",
    "                if model_rawpreds[s-1][i_modelcorr].shape[0] == model1win_predval.shape[0] + model2win_predval.shape[0] + model12win_predval.shape[0]:\n",
    "                    # print('SEED: '+str(s))\n",
    "                    # Percentage of model predictions correct due to just ENSO/MJO/ENSO&MJO:\n",
    "                    model1_allcorr_fracpred[s-1]  = (model1win_predval.shape[0]/model_rawpreds[s-1][i_modelcorr].shape[0])\n",
    "                    model2_allcorr_fracpred[s-1]  = (model2win_predval.shape[0]/model_rawpreds[s-1][i_modelcorr].shape[0])\n",
    "                    model12_allcorr_fracpred[s-1] = (model12win_predval.shape[0]/model_rawpreds[s-1][i_modelcorr].shape[0])        \n",
    "\n",
    "            \n",
    "            \n",
    "                # --------------------------------------------------------------------------------------\n",
    "                # --------- confident predictions contribution: ----------------------------------------\n",
    "                # --------------------------------------------------------------------------------------\n",
    "                i_model1_samefinalconfpred = model1pred[i_conf_predval]==predval[i_conf_predval]\n",
    "                i_model2_samefinalconfpred = model2pred[i_conf_predval]==predval[i_conf_predval]\n",
    "                \n",
    "                # terminology: \"win\" = modelX prediction is also full model prediction\n",
    "                # model X same as final prediction & model ~X does not have that prediction\n",
    "                i_model1win = i_model1_samefinalconfpred & ~i_model2_samefinalconfpred\n",
    "                i_model2win = i_model2_samefinalconfpred & ~i_model1_samefinalconfpred\n",
    "                # model 1&2 have same final prediction\n",
    "                i_model12win = i_model1_samefinalconfpred & i_model2_samefinalconfpred\n",
    "                \n",
    "                \n",
    "                # number of predictions of model(X) predicted class that is also full model prediction\n",
    "                n_model1win_predval = model1pred[i_conf_predval][i_model1win].shape[0]\n",
    "                n_model2win_predval = model2pred[i_conf_predval][i_model2win].shape[0]\n",
    "                n_model12win_predval = predval[i_conf_predval][i_model12win].shape[0]\n",
    "\n",
    "                \n",
    "                # these shapes should be equal (True), assuming ~i_model1corr & ~i_model2corr & i_modelcorr doesnt happen\n",
    "                if predval[i_conf_predval].shape[0] == n_model1win_predval + n_model2win_predval + n_model12win_predval:\n",
    "                    # print('SEED: '+str(s))\n",
    "                    # Percentage of model predictions correct due to just ENSO/MJO/ENSO&MJO:\n",
    "                    model1_conf_fracpred[s-1]  = (n_model1win_predval/predval[i_conf_predval].shape[0])\n",
    "                    model2_conf_fracpred[s-1]  = (n_model2win_predval/predval[i_conf_predval].shape[0])\n",
    "                    model12_conf_fracpred[s-1] = (n_model12win_predval/predval[i_conf_predval].shape[0]) \n",
    "                \n",
    "                \n",
    "                \n",
    "                # --------------------------------------------------------------------------------------\n",
    "                # --------- confident & correct predictions contribution:-------------------------------\n",
    "                # --------------------------------------------------------------------------------------\n",
    "                # Where ENSO/MJO/final model (model 1/model 2/total) are correct\n",
    "                i_model1_confcorr = model1pred[i_conf_predval]==Ytest[i_conf_predval]\n",
    "                i_model2_confcorr = model2pred[i_conf_predval]==Ytest[i_conf_predval]\n",
    "                i_model_confcorr  = predval[i_conf_predval]==Ytest[i_conf_predval]\n",
    "\n",
    "                # terminology: \"win\" = modelX prediction is also (correct) full model prediction\n",
    "                # model X correct & model correct (model ~X not correct)\n",
    "                i_model1win = i_model1_confcorr & i_model_confcorr & ~i_model2_confcorr\n",
    "                i_model2win = i_model2_confcorr & i_model_confcorr & ~i_model1_confcorr\n",
    "                # model 1&2 correct & model correct\n",
    "                i_model12win = i_model1_confcorr & i_model2_confcorr & i_model_confcorr\n",
    "\n",
    "                # For correct predictions: model(X) values & predicted class when also full model prediction\n",
    "                n_model1win_predval = model1pred[i_conf_predval][i_model1win].shape[0]\n",
    "                n_model2win_predval = model2pred[i_conf_predval][i_model2win].shape[0]\n",
    "                n_model12win_predval = predval[i_conf_predval][i_model12win].shape[0]\n",
    "                \n",
    "                \n",
    "                # these shapes should be equal (True), assuming ~i_model1corr & ~i_model2corr & i_modelcorr doesnt happen\n",
    "                if predval[i_conf_predval][i_model_confcorr].shape[0] == n_model1win_predval + n_model2win_predval + n_model12win_predval:\n",
    "                    # print('SEED: '+str(s))\n",
    "                    # Percentage of model predictions correct due to just ENSO/MJO/ENSO&MJO:\n",
    "                    model1_confcorr_fracpred[s-1]  = (n_model1win_predval/predval[i_conf_predval][i_model_confcorr].shape[0])\n",
    "                    model2_confcorr_fracpred[s-1]  = (n_model2win_predval/predval[i_conf_predval][i_model_confcorr].shape[0])\n",
    "                    model12_confcorr_fracpred[s-1] = (n_model12win_predval/predval[i_conf_predval][i_model_confcorr].shape[0])\n",
    "            \n",
    "            if SAVE:\n",
    "                print('saving')\n",
    "                ddir_save = '/glade/scratch/kjmayer/DATA/ENSOvsMJO/data/'\n",
    "                \n",
    "                finame_confvsacc = 'confvsacc_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "                np.save(ddir_save+finame_confvsacc, confvsacc)\n",
    "\n",
    "                finame_rawpred = 'model1_rawpred_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "                np.save(ddir_save+finame_rawpred, model1_rawpreds)\n",
    "                finame_rawpred = 'model2_rawpred_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "                np.save(ddir_save+finame_rawpred, model2_rawpreds)\n",
    "                finame_rawpred = 'model_rawpred_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "                np.save(ddir_save+finame_rawpred, model_rawpreds)\n",
    "\n",
    "                finame_fracpred = 'model1_fracpred_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "                np.save(ddir_save+finame_fracpred, model1_allcorr_fracpred)\n",
    "                finame_fracpred = 'model2_fracpred_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "                np.save(ddir_save+finame_fracpred, model2_allcorr_fracpred)\n",
    "                finame_fracpred = 'model12_fracpred_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "                np.save(ddir_save+finame_fracpred, model12_allcorr_fracpred)\n",
    "                \n",
    "                finame_fracpred = 'model1_allfracpred_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "                np.save(ddir_save+finame_fracpred, model1_all_fracpred)\n",
    "                finame_fracpred = 'model2_allfracpred_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "                np.save(ddir_save+finame_fracpred, model2_all_fracpred)\n",
    "                finame_fracpred = 'model12_allfracpred_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "                np.save(ddir_save+finame_fracpred, model12_all_fracpred)\n",
    "                \n",
    "                finame_fracpred = 'model1_conffracpred_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "                np.save(ddir_save+finame_fracpred, model1_conf_fracpred)\n",
    "                finame_fracpred = 'model2_conffracpred_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "                np.save(ddir_save+finame_fracpred, model2_conf_fracpred)\n",
    "                finame_fracpred = 'model12_conffracpred_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "                np.save(ddir_save+finame_fracpred, model12_conf_fracpred)\n",
    "                \n",
    "                finame_fracpred = 'model1_confcorrfracpred_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "                np.save(ddir_save+finame_fracpred, model1_confcorr_fracpred)\n",
    "                finame_fracpred = 'model2_confcorrfracpred_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "                np.save(ddir_save+finame_fracpred, model2_confcorr_fracpred)\n",
    "                finame_fracpred = 'model12_confcorrfracpred_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "                np.save(ddir_save+finame_fracpred, model12_confcorr_fracpred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65eb0a5-a0e5-404f-80ca-61c82fa59e58",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Confident and Correct Fraction of Predictions, split by prediction sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96cb61a6-1e7b-41f3-ac00-fabbbbbcce2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEAD: 7\n",
      "AVG: 2\n",
      "LEAD: 7\n",
      "AVG: 3\n",
      "LEAD: 7\n",
      "AVG: 4\n",
      "LEAD: 7\n",
      "AVG: 5\n",
      "LEAD: 7\n",
      "AVG: 6\n",
      "LEAD: 7\n",
      "AVG: 7\n",
      "LEAD: 7\n",
      "AVG: 8\n",
      "LEAD: 7\n",
      "AVG: 9\n",
      "LEAD: 7\n",
      "AVG: 10\n",
      "LEAD: 7\n",
      "AVG: 11\n",
      "LEAD: 7\n",
      "AVG: 12\n",
      "LEAD: 7\n",
      "AVG: 13\n",
      "LEAD: 7\n",
      "AVG: 14\n",
      "LEAD: 7\n",
      "AVG: 15\n",
      "LEAD: 7\n",
      "AVG: 16\n",
      "LEAD: 7\n",
      "AVG: 17\n",
      "LEAD: 7\n",
      "AVG: 18\n",
      "LEAD: 7\n",
      "AVG: 19\n",
      "LEAD: 7\n",
      "AVG: 20\n",
      "LEAD: 7\n",
      "AVG: 21\n",
      "LEAD: 7\n",
      "AVG: 22\n",
      "LEAD: 7\n",
      "AVG: 23\n",
      "LEAD: 7\n",
      "AVG: 24\n",
      "LEAD: 7\n",
      "AVG: 25\n",
      "LEAD: 7\n",
      "AVG: 26\n",
      "LEAD: 7\n",
      "AVG: 27\n",
      "LEAD: 7\n",
      "AVG: 28\n",
      "LEAD: 7\n",
      "AVG: 29\n",
      "LEAD: 7\n",
      "AVG: 30\n",
      "LEAD: 7\n",
      "AVG: 31\n",
      "LEAD: 8\n",
      "AVG: 2\n",
      "LEAD: 8\n",
      "AVG: 3\n",
      "LEAD: 8\n",
      "AVG: 4\n",
      "LEAD: 8\n",
      "AVG: 5\n",
      "LEAD: 8\n",
      "AVG: 6\n",
      "LEAD: 8\n",
      "AVG: 7\n",
      "LEAD: 8\n",
      "AVG: 8\n",
      "LEAD: 8\n",
      "AVG: 9\n",
      "LEAD: 8\n",
      "AVG: 10\n",
      "LEAD: 8\n",
      "AVG: 11\n",
      "LEAD: 8\n",
      "AVG: 12\n",
      "LEAD: 8\n",
      "AVG: 13\n",
      "LEAD: 8\n",
      "AVG: 14\n",
      "LEAD: 8\n",
      "AVG: 15\n",
      "LEAD: 8\n",
      "AVG: 16\n",
      "LEAD: 8\n",
      "AVG: 17\n",
      "LEAD: 8\n",
      "AVG: 18\n",
      "LEAD: 8\n",
      "AVG: 19\n",
      "LEAD: 8\n",
      "AVG: 20\n",
      "LEAD: 8\n",
      "AVG: 21\n",
      "LEAD: 8\n",
      "AVG: 22\n",
      "LEAD: 8\n",
      "AVG: 23\n",
      "LEAD: 8\n",
      "AVG: 24\n",
      "LEAD: 8\n",
      "AVG: 25\n",
      "LEAD: 8\n",
      "AVG: 26\n",
      "LEAD: 8\n",
      "AVG: 27\n",
      "LEAD: 8\n",
      "AVG: 28\n",
      "LEAD: 8\n",
      "AVG: 29\n",
      "LEAD: 8\n",
      "AVG: 30\n",
      "LEAD: 8\n",
      "AVG: 31\n",
      "LEAD: 9\n",
      "AVG: 2\n",
      "LEAD: 9\n",
      "AVG: 3\n",
      "LEAD: 9\n",
      "AVG: 4\n",
      "LEAD: 9\n",
      "AVG: 5\n",
      "LEAD: 9\n",
      "AVG: 6\n",
      "LEAD: 9\n",
      "AVG: 7\n",
      "LEAD: 9\n",
      "AVG: 8\n",
      "LEAD: 9\n",
      "AVG: 9\n",
      "LEAD: 9\n",
      "AVG: 10\n",
      "LEAD: 9\n",
      "AVG: 11\n",
      "LEAD: 9\n",
      "AVG: 12\n",
      "LEAD: 9\n",
      "AVG: 13\n",
      "LEAD: 9\n",
      "AVG: 14\n",
      "LEAD: 9\n",
      "AVG: 15\n",
      "LEAD: 9\n",
      "AVG: 16\n",
      "LEAD: 9\n",
      "AVG: 17\n",
      "LEAD: 9\n",
      "AVG: 18\n",
      "LEAD: 9\n",
      "AVG: 19\n",
      "LEAD: 9\n",
      "AVG: 20\n",
      "LEAD: 9\n",
      "AVG: 21\n",
      "LEAD: 9\n",
      "AVG: 22\n",
      "LEAD: 9\n",
      "AVG: 23\n",
      "LEAD: 9\n",
      "AVG: 24\n",
      "LEAD: 9\n",
      "AVG: 25\n",
      "LEAD: 9\n",
      "AVG: 26\n",
      "LEAD: 9\n",
      "AVG: 27\n",
      "LEAD: 9\n",
      "AVG: 28\n",
      "LEAD: 9\n",
      "AVG: 29\n",
      "LEAD: 9\n",
      "AVG: 30\n",
      "LEAD: 9\n",
      "AVG: 31\n",
      "LEAD: 10\n",
      "AVG: 2\n",
      "LEAD: 10\n",
      "AVG: 3\n",
      "LEAD: 10\n",
      "AVG: 4\n",
      "LEAD: 10\n",
      "AVG: 5\n",
      "LEAD: 10\n",
      "AVG: 6\n",
      "LEAD: 10\n",
      "AVG: 7\n",
      "LEAD: 10\n",
      "AVG: 8\n",
      "LEAD: 10\n",
      "AVG: 9\n",
      "LEAD: 10\n",
      "AVG: 10\n",
      "LEAD: 10\n",
      "AVG: 11\n",
      "LEAD: 10\n",
      "AVG: 12\n",
      "LEAD: 10\n",
      "AVG: 13\n",
      "LEAD: 10\n",
      "AVG: 14\n",
      "LEAD: 10\n",
      "AVG: 15\n",
      "LEAD: 10\n",
      "AVG: 16\n",
      "LEAD: 10\n",
      "AVG: 17\n",
      "LEAD: 10\n",
      "AVG: 18\n",
      "LEAD: 10\n",
      "AVG: 19\n",
      "LEAD: 10\n",
      "AVG: 20\n",
      "LEAD: 10\n",
      "AVG: 21\n",
      "LEAD: 10\n",
      "AVG: 22\n",
      "LEAD: 10\n",
      "AVG: 23\n",
      "LEAD: 10\n",
      "AVG: 24\n",
      "LEAD: 10\n",
      "AVG: 25\n",
      "LEAD: 10\n",
      "AVG: 26\n",
      "LEAD: 10\n",
      "AVG: 27\n",
      "LEAD: 10\n",
      "AVG: 28\n",
      "LEAD: 10\n",
      "AVG: 29\n",
      "LEAD: 10\n",
      "AVG: 30\n",
      "LEAD: 10\n",
      "AVG: 31\n",
      "LEAD: 11\n",
      "AVG: 2\n",
      "LEAD: 11\n",
      "AVG: 3\n",
      "LEAD: 11\n",
      "AVG: 4\n",
      "LEAD: 11\n",
      "AVG: 5\n",
      "LEAD: 11\n",
      "AVG: 6\n",
      "LEAD: 11\n",
      "AVG: 7\n",
      "LEAD: 11\n",
      "AVG: 8\n",
      "LEAD: 11\n",
      "AVG: 9\n",
      "LEAD: 11\n",
      "AVG: 10\n",
      "LEAD: 11\n",
      "AVG: 11\n",
      "LEAD: 11\n",
      "AVG: 12\n",
      "LEAD: 11\n",
      "AVG: 13\n",
      "LEAD: 11\n",
      "AVG: 14\n",
      "LEAD: 11\n",
      "AVG: 15\n",
      "LEAD: 11\n",
      "AVG: 16\n",
      "LEAD: 11\n",
      "AVG: 17\n",
      "LEAD: 11\n",
      "AVG: 18\n",
      "LEAD: 11\n",
      "AVG: 19\n",
      "LEAD: 11\n",
      "AVG: 20\n",
      "LEAD: 11\n",
      "AVG: 21\n",
      "LEAD: 11\n",
      "AVG: 22\n",
      "LEAD: 11\n",
      "AVG: 23\n",
      "LEAD: 11\n",
      "AVG: 24\n",
      "LEAD: 11\n",
      "AVG: 25\n",
      "LEAD: 11\n",
      "AVG: 26\n",
      "LEAD: 11\n",
      "AVG: 27\n",
      "LEAD: 11\n",
      "AVG: 28\n",
      "LEAD: 11\n",
      "AVG: 29\n",
      "LEAD: 11\n",
      "AVG: 30\n",
      "LEAD: 11\n",
      "AVG: 31\n",
      "LEAD: 12\n",
      "AVG: 2\n",
      "LEAD: 12\n",
      "AVG: 3\n",
      "LEAD: 12\n",
      "AVG: 4\n",
      "LEAD: 12\n",
      "AVG: 5\n",
      "LEAD: 12\n",
      "AVG: 6\n",
      "LEAD: 12\n",
      "AVG: 7\n",
      "LEAD: 12\n",
      "AVG: 8\n",
      "LEAD: 12\n",
      "AVG: 9\n",
      "LEAD: 12\n",
      "AVG: 10\n",
      "LEAD: 12\n",
      "AVG: 11\n",
      "LEAD: 12\n",
      "AVG: 12\n",
      "LEAD: 12\n",
      "AVG: 13\n",
      "LEAD: 12\n",
      "AVG: 14\n",
      "LEAD: 12\n",
      "AVG: 15\n",
      "LEAD: 12\n",
      "AVG: 16\n",
      "LEAD: 12\n",
      "AVG: 17\n",
      "LEAD: 12\n",
      "AVG: 18\n",
      "LEAD: 12\n",
      "AVG: 19\n",
      "LEAD: 12\n",
      "AVG: 20\n",
      "LEAD: 12\n",
      "AVG: 21\n",
      "LEAD: 12\n",
      "AVG: 22\n",
      "LEAD: 12\n",
      "AVG: 23\n",
      "LEAD: 12\n",
      "AVG: 24\n",
      "LEAD: 12\n",
      "AVG: 25\n",
      "LEAD: 12\n",
      "AVG: 26\n",
      "LEAD: 12\n",
      "AVG: 27\n",
      "LEAD: 12\n",
      "AVG: 28\n",
      "LEAD: 12\n",
      "AVG: 29\n",
      "LEAD: 12\n",
      "AVG: 30\n",
      "LEAD: 12\n",
      "AVG: 31\n",
      "LEAD: 13\n",
      "AVG: 2\n",
      "LEAD: 13\n",
      "AVG: 3\n",
      "LEAD: 13\n",
      "AVG: 4\n",
      "LEAD: 13\n",
      "AVG: 5\n",
      "LEAD: 13\n",
      "AVG: 6\n",
      "LEAD: 13\n",
      "AVG: 7\n",
      "LEAD: 13\n",
      "AVG: 8\n",
      "LEAD: 13\n",
      "AVG: 9\n",
      "LEAD: 13\n",
      "AVG: 10\n",
      "LEAD: 13\n",
      "AVG: 11\n",
      "LEAD: 13\n",
      "AVG: 12\n",
      "LEAD: 13\n",
      "AVG: 13\n",
      "LEAD: 13\n",
      "AVG: 14\n",
      "LEAD: 13\n",
      "AVG: 15\n",
      "LEAD: 13\n",
      "AVG: 16\n",
      "LEAD: 13\n",
      "AVG: 17\n",
      "LEAD: 13\n",
      "AVG: 18\n",
      "LEAD: 13\n",
      "AVG: 19\n",
      "LEAD: 13\n",
      "AVG: 20\n",
      "LEAD: 13\n",
      "AVG: 21\n",
      "LEAD: 13\n",
      "AVG: 22\n",
      "LEAD: 13\n",
      "AVG: 23\n",
      "LEAD: 13\n",
      "AVG: 24\n",
      "LEAD: 13\n",
      "AVG: 25\n",
      "LEAD: 13\n",
      "AVG: 26\n",
      "LEAD: 13\n",
      "AVG: 27\n",
      "LEAD: 13\n",
      "AVG: 28\n",
      "LEAD: 13\n",
      "AVG: 29\n",
      "LEAD: 13\n",
      "AVG: 30\n",
      "LEAD: 13\n",
      "AVG: 31\n",
      "LEAD: 14\n",
      "AVG: 2\n",
      "LEAD: 14\n",
      "AVG: 3\n",
      "LEAD: 14\n",
      "AVG: 4\n",
      "LEAD: 14\n",
      "AVG: 5\n",
      "LEAD: 14\n",
      "AVG: 6\n",
      "LEAD: 14\n",
      "AVG: 7\n",
      "LEAD: 14\n",
      "AVG: 8\n",
      "LEAD: 14\n",
      "AVG: 9\n",
      "LEAD: 14\n",
      "AVG: 10\n",
      "LEAD: 14\n",
      "AVG: 11\n",
      "LEAD: 14\n",
      "AVG: 12\n",
      "LEAD: 14\n",
      "AVG: 13\n",
      "LEAD: 14\n",
      "AVG: 14\n",
      "LEAD: 14\n",
      "AVG: 15\n",
      "LEAD: 14\n",
      "AVG: 16\n",
      "LEAD: 14\n",
      "AVG: 17\n",
      "LEAD: 14\n",
      "AVG: 18\n",
      "LEAD: 14\n",
      "AVG: 19\n",
      "LEAD: 14\n",
      "AVG: 20\n",
      "LEAD: 14\n",
      "AVG: 21\n",
      "LEAD: 14\n",
      "AVG: 22\n",
      "LEAD: 14\n",
      "AVG: 23\n",
      "LEAD: 14\n",
      "AVG: 24\n",
      "LEAD: 14\n",
      "AVG: 25\n",
      "LEAD: 14\n",
      "AVG: 26\n",
      "LEAD: 14\n",
      "AVG: 27\n",
      "LEAD: 14\n",
      "AVG: 28\n",
      "LEAD: 14\n",
      "AVG: 29\n",
      "LEAD: 14\n",
      "AVG: 30\n",
      "LEAD: 14\n",
      "AVG: 31\n",
      "LEAD: 15\n",
      "AVG: 2\n",
      "LEAD: 15\n",
      "AVG: 3\n",
      "LEAD: 15\n",
      "AVG: 4\n",
      "LEAD: 15\n",
      "AVG: 5\n",
      "LEAD: 15\n",
      "AVG: 6\n",
      "LEAD: 15\n",
      "AVG: 7\n",
      "LEAD: 15\n",
      "AVG: 8\n",
      "LEAD: 15\n",
      "AVG: 9\n",
      "LEAD: 15\n",
      "AVG: 10\n",
      "LEAD: 15\n",
      "AVG: 11\n",
      "LEAD: 15\n",
      "AVG: 12\n",
      "LEAD: 15\n",
      "AVG: 13\n",
      "LEAD: 15\n",
      "AVG: 14\n",
      "LEAD: 15\n",
      "AVG: 15\n",
      "LEAD: 15\n",
      "AVG: 16\n",
      "LEAD: 15\n",
      "AVG: 17\n",
      "LEAD: 15\n",
      "AVG: 18\n",
      "LEAD: 15\n",
      "AVG: 19\n",
      "LEAD: 15\n",
      "AVG: 20\n",
      "LEAD: 15\n",
      "AVG: 21\n",
      "LEAD: 15\n",
      "AVG: 22\n",
      "LEAD: 15\n",
      "AVG: 23\n",
      "LEAD: 15\n",
      "AVG: 24\n",
      "LEAD: 15\n",
      "AVG: 25\n",
      "LEAD: 15\n",
      "AVG: 26\n",
      "LEAD: 15\n",
      "AVG: 27\n",
      "LEAD: 15\n",
      "AVG: 28\n",
      "LEAD: 15\n",
      "AVG: 29\n",
      "LEAD: 15\n",
      "AVG: 30\n",
      "LEAD: 15\n",
      "AVG: 31\n",
      "LEAD: 16\n",
      "AVG: 2\n",
      "LEAD: 16\n",
      "AVG: 3\n",
      "LEAD: 16\n",
      "AVG: 4\n",
      "LEAD: 16\n",
      "AVG: 5\n",
      "LEAD: 16\n",
      "AVG: 6\n",
      "LEAD: 16\n",
      "AVG: 7\n",
      "LEAD: 16\n",
      "AVG: 8\n",
      "LEAD: 16\n",
      "AVG: 9\n",
      "LEAD: 16\n",
      "AVG: 10\n",
      "LEAD: 16\n",
      "AVG: 11\n",
      "LEAD: 16\n",
      "AVG: 12\n",
      "LEAD: 16\n",
      "AVG: 13\n",
      "LEAD: 16\n",
      "AVG: 14\n",
      "LEAD: 16\n",
      "AVG: 15\n",
      "LEAD: 16\n",
      "AVG: 16\n",
      "LEAD: 16\n",
      "AVG: 17\n",
      "LEAD: 16\n",
      "AVG: 18\n",
      "LEAD: 16\n",
      "AVG: 19\n",
      "LEAD: 16\n",
      "AVG: 20\n",
      "LEAD: 16\n",
      "AVG: 21\n",
      "LEAD: 16\n",
      "AVG: 22\n",
      "LEAD: 16\n",
      "AVG: 23\n",
      "LEAD: 16\n",
      "AVG: 24\n",
      "LEAD: 16\n",
      "AVG: 25\n",
      "LEAD: 16\n",
      "AVG: 26\n",
      "LEAD: 16\n",
      "AVG: 27\n",
      "LEAD: 16\n",
      "AVG: 28\n",
      "LEAD: 16\n",
      "AVG: 29\n",
      "LEAD: 16\n",
      "AVG: 30\n",
      "LEAD: 16\n",
      "AVG: 31\n",
      "LEAD: 17\n",
      "AVG: 2\n",
      "LEAD: 17\n",
      "AVG: 3\n",
      "LEAD: 17\n",
      "AVG: 4\n",
      "LEAD: 17\n",
      "AVG: 5\n",
      "LEAD: 17\n",
      "AVG: 6\n",
      "LEAD: 17\n",
      "AVG: 7\n",
      "LEAD: 17\n",
      "AVG: 8\n",
      "LEAD: 17\n",
      "AVG: 9\n",
      "LEAD: 17\n",
      "AVG: 10\n",
      "LEAD: 17\n",
      "AVG: 11\n",
      "LEAD: 17\n",
      "AVG: 12\n",
      "LEAD: 17\n",
      "AVG: 13\n",
      "LEAD: 17\n",
      "AVG: 14\n",
      "LEAD: 17\n",
      "AVG: 15\n",
      "LEAD: 17\n",
      "AVG: 16\n",
      "LEAD: 17\n",
      "AVG: 17\n",
      "LEAD: 17\n",
      "AVG: 18\n",
      "LEAD: 17\n",
      "AVG: 19\n",
      "LEAD: 17\n",
      "AVG: 20\n",
      "LEAD: 17\n",
      "AVG: 21\n",
      "LEAD: 17\n",
      "AVG: 22\n",
      "LEAD: 17\n",
      "AVG: 23\n",
      "LEAD: 17\n",
      "AVG: 24\n",
      "LEAD: 17\n",
      "AVG: 25\n",
      "LEAD: 17\n",
      "AVG: 26\n",
      "LEAD: 17\n",
      "AVG: 27\n",
      "LEAD: 17\n",
      "AVG: 28\n",
      "LEAD: 17\n",
      "AVG: 29\n",
      "LEAD: 17\n",
      "AVG: 30\n",
      "LEAD: 17\n",
      "AVG: 31\n",
      "LEAD: 18\n",
      "AVG: 2\n",
      "LEAD: 18\n",
      "AVG: 3\n",
      "LEAD: 18\n",
      "AVG: 4\n",
      "LEAD: 18\n",
      "AVG: 5\n",
      "LEAD: 18\n",
      "AVG: 6\n",
      "LEAD: 18\n",
      "AVG: 7\n",
      "LEAD: 18\n",
      "AVG: 8\n",
      "LEAD: 18\n",
      "AVG: 9\n",
      "LEAD: 18\n",
      "AVG: 10\n",
      "LEAD: 18\n",
      "AVG: 11\n",
      "LEAD: 18\n",
      "AVG: 12\n",
      "LEAD: 18\n",
      "AVG: 13\n",
      "LEAD: 18\n",
      "AVG: 14\n",
      "LEAD: 18\n",
      "AVG: 15\n",
      "LEAD: 18\n",
      "AVG: 16\n",
      "LEAD: 18\n",
      "AVG: 17\n",
      "LEAD: 18\n",
      "AVG: 18\n",
      "LEAD: 18\n",
      "AVG: 19\n",
      "LEAD: 18\n",
      "AVG: 20\n",
      "LEAD: 18\n",
      "AVG: 21\n",
      "LEAD: 18\n",
      "AVG: 22\n",
      "LEAD: 18\n",
      "AVG: 23\n",
      "LEAD: 18\n",
      "AVG: 24\n",
      "LEAD: 18\n",
      "AVG: 25\n",
      "LEAD: 18\n",
      "AVG: 26\n",
      "LEAD: 18\n",
      "AVG: 27\n",
      "LEAD: 18\n",
      "AVG: 28\n",
      "LEAD: 18\n",
      "AVG: 29\n",
      "LEAD: 18\n",
      "AVG: 30\n",
      "LEAD: 18\n",
      "AVG: 31\n",
      "LEAD: 19\n",
      "AVG: 2\n",
      "LEAD: 19\n",
      "AVG: 3\n",
      "LEAD: 19\n",
      "AVG: 4\n",
      "LEAD: 19\n",
      "AVG: 5\n",
      "LEAD: 19\n",
      "AVG: 6\n",
      "LEAD: 19\n",
      "AVG: 7\n",
      "LEAD: 19\n",
      "AVG: 8\n",
      "LEAD: 19\n",
      "AVG: 9\n",
      "LEAD: 19\n",
      "AVG: 10\n",
      "LEAD: 19\n",
      "AVG: 11\n",
      "LEAD: 19\n",
      "AVG: 12\n",
      "LEAD: 19\n",
      "AVG: 13\n",
      "LEAD: 19\n",
      "AVG: 14\n",
      "LEAD: 19\n",
      "AVG: 15\n",
      "LEAD: 19\n",
      "AVG: 16\n",
      "LEAD: 19\n",
      "AVG: 17\n",
      "LEAD: 19\n",
      "AVG: 18\n",
      "LEAD: 19\n",
      "AVG: 19\n",
      "LEAD: 19\n",
      "AVG: 20\n",
      "LEAD: 19\n",
      "AVG: 21\n",
      "LEAD: 19\n",
      "AVG: 22\n",
      "LEAD: 19\n",
      "AVG: 23\n",
      "LEAD: 19\n",
      "AVG: 24\n",
      "LEAD: 19\n",
      "AVG: 25\n",
      "LEAD: 19\n",
      "AVG: 26\n",
      "LEAD: 19\n",
      "AVG: 27\n",
      "LEAD: 19\n",
      "AVG: 28\n",
      "LEAD: 19\n",
      "AVG: 29\n",
      "LEAD: 19\n",
      "AVG: 30\n",
      "LEAD: 19\n",
      "AVG: 31\n",
      "LEAD: 20\n",
      "AVG: 2\n",
      "LEAD: 20\n",
      "AVG: 3\n",
      "LEAD: 20\n",
      "AVG: 4\n",
      "LEAD: 20\n",
      "AVG: 5\n",
      "LEAD: 20\n",
      "AVG: 6\n",
      "LEAD: 20\n",
      "AVG: 7\n",
      "LEAD: 20\n",
      "AVG: 8\n",
      "LEAD: 20\n",
      "AVG: 9\n",
      "LEAD: 20\n",
      "AVG: 10\n",
      "LEAD: 20\n",
      "AVG: 11\n",
      "LEAD: 20\n",
      "AVG: 12\n",
      "LEAD: 20\n",
      "AVG: 13\n",
      "LEAD: 20\n",
      "AVG: 14\n",
      "LEAD: 20\n",
      "AVG: 15\n",
      "LEAD: 20\n",
      "AVG: 16\n",
      "LEAD: 20\n",
      "AVG: 17\n",
      "LEAD: 20\n",
      "AVG: 18\n",
      "LEAD: 20\n",
      "AVG: 19\n",
      "LEAD: 20\n",
      "AVG: 20\n",
      "LEAD: 20\n",
      "AVG: 21\n",
      "LEAD: 20\n",
      "AVG: 22\n",
      "LEAD: 20\n",
      "AVG: 23\n",
      "LEAD: 20\n",
      "AVG: 24\n",
      "LEAD: 20\n",
      "AVG: 25\n",
      "LEAD: 20\n",
      "AVG: 26\n",
      "LEAD: 20\n",
      "AVG: 27\n",
      "LEAD: 20\n",
      "AVG: 28\n",
      "LEAD: 20\n",
      "AVG: 29\n",
      "LEAD: 20\n",
      "AVG: 30\n",
      "LEAD: 20\n",
      "AVG: 31\n",
      "LEAD: 21\n",
      "AVG: 2\n",
      "LEAD: 21\n",
      "AVG: 3\n",
      "LEAD: 21\n",
      "AVG: 4\n",
      "LEAD: 21\n",
      "AVG: 5\n",
      "LEAD: 21\n",
      "AVG: 6\n",
      "LEAD: 21\n",
      "AVG: 7\n",
      "LEAD: 21\n",
      "AVG: 8\n",
      "LEAD: 21\n",
      "AVG: 9\n",
      "LEAD: 21\n",
      "AVG: 10\n",
      "LEAD: 21\n",
      "AVG: 11\n",
      "LEAD: 21\n",
      "AVG: 12\n",
      "LEAD: 21\n",
      "AVG: 13\n",
      "LEAD: 21\n",
      "AVG: 14\n",
      "LEAD: 21\n",
      "AVG: 15\n",
      "LEAD: 21\n",
      "AVG: 16\n",
      "LEAD: 21\n",
      "AVG: 17\n",
      "LEAD: 21\n",
      "AVG: 18\n",
      "LEAD: 21\n",
      "AVG: 19\n",
      "LEAD: 21\n",
      "AVG: 20\n",
      "LEAD: 21\n",
      "AVG: 21\n",
      "LEAD: 21\n",
      "AVG: 22\n",
      "LEAD: 21\n",
      "AVG: 23\n",
      "LEAD: 21\n",
      "AVG: 24\n",
      "LEAD: 21\n",
      "AVG: 25\n",
      "LEAD: 21\n",
      "AVG: 26\n",
      "LEAD: 21\n",
      "AVG: 27\n",
      "LEAD: 21\n",
      "AVG: 28\n",
      "LEAD: 21\n",
      "AVG: 29\n",
      "LEAD: 21\n",
      "AVG: 30\n",
      "LEAD: 21\n",
      "AVG: 31\n",
      "LEAD: 22\n",
      "AVG: 2\n",
      "LEAD: 22\n",
      "AVG: 3\n",
      "LEAD: 22\n",
      "AVG: 4\n",
      "LEAD: 22\n",
      "AVG: 5\n",
      "LEAD: 22\n",
      "AVG: 6\n",
      "LEAD: 22\n",
      "AVG: 7\n",
      "LEAD: 22\n",
      "AVG: 8\n",
      "LEAD: 22\n",
      "AVG: 9\n",
      "LEAD: 22\n",
      "AVG: 10\n",
      "LEAD: 22\n",
      "AVG: 11\n",
      "LEAD: 22\n",
      "AVG: 12\n",
      "LEAD: 22\n",
      "AVG: 13\n",
      "LEAD: 22\n",
      "AVG: 14\n",
      "LEAD: 22\n",
      "AVG: 15\n",
      "LEAD: 22\n",
      "AVG: 16\n",
      "LEAD: 22\n",
      "AVG: 17\n",
      "LEAD: 22\n",
      "AVG: 18\n",
      "LEAD: 22\n",
      "AVG: 19\n",
      "LEAD: 22\n",
      "AVG: 20\n",
      "LEAD: 22\n",
      "AVG: 21\n",
      "LEAD: 22\n",
      "AVG: 22\n",
      "LEAD: 22\n",
      "AVG: 23\n",
      "LEAD: 22\n",
      "AVG: 24\n",
      "LEAD: 22\n",
      "AVG: 25\n",
      "LEAD: 22\n",
      "AVG: 26\n",
      "LEAD: 22\n",
      "AVG: 27\n",
      "LEAD: 22\n",
      "AVG: 28\n",
      "LEAD: 22\n",
      "AVG: 29\n",
      "LEAD: 22\n",
      "AVG: 30\n",
      "LEAD: 22\n",
      "AVG: 31\n",
      "LEAD: 23\n",
      "AVG: 2\n",
      "LEAD: 23\n",
      "AVG: 3\n",
      "LEAD: 23\n",
      "AVG: 4\n",
      "LEAD: 23\n",
      "AVG: 5\n",
      "LEAD: 23\n",
      "AVG: 6\n",
      "LEAD: 23\n",
      "AVG: 7\n",
      "LEAD: 23\n",
      "AVG: 8\n",
      "LEAD: 23\n",
      "AVG: 9\n",
      "LEAD: 23\n",
      "AVG: 10\n",
      "LEAD: 23\n",
      "AVG: 11\n",
      "LEAD: 23\n",
      "AVG: 12\n",
      "LEAD: 23\n",
      "AVG: 13\n",
      "LEAD: 23\n",
      "AVG: 14\n",
      "LEAD: 23\n",
      "AVG: 15\n",
      "LEAD: 23\n",
      "AVG: 16\n",
      "LEAD: 23\n",
      "AVG: 17\n",
      "LEAD: 23\n",
      "AVG: 18\n",
      "LEAD: 23\n",
      "AVG: 19\n",
      "LEAD: 23\n",
      "AVG: 20\n",
      "LEAD: 23\n",
      "AVG: 21\n",
      "LEAD: 23\n",
      "AVG: 22\n",
      "LEAD: 23\n",
      "AVG: 23\n",
      "LEAD: 23\n",
      "AVG: 24\n",
      "LEAD: 23\n",
      "AVG: 25\n",
      "LEAD: 23\n",
      "AVG: 26\n",
      "LEAD: 23\n",
      "AVG: 27\n",
      "LEAD: 23\n",
      "AVG: 28\n",
      "LEAD: 23\n",
      "AVG: 29\n",
      "LEAD: 23\n",
      "AVG: 30\n",
      "LEAD: 23\n",
      "AVG: 31\n",
      "LEAD: 24\n",
      "AVG: 2\n",
      "LEAD: 24\n",
      "AVG: 3\n",
      "LEAD: 24\n",
      "AVG: 4\n",
      "LEAD: 24\n",
      "AVG: 5\n",
      "LEAD: 24\n",
      "AVG: 6\n",
      "LEAD: 24\n",
      "AVG: 7\n",
      "LEAD: 24\n",
      "AVG: 8\n",
      "LEAD: 24\n",
      "AVG: 9\n",
      "LEAD: 24\n",
      "AVG: 10\n",
      "LEAD: 24\n",
      "AVG: 11\n",
      "LEAD: 24\n",
      "AVG: 12\n",
      "LEAD: 24\n",
      "AVG: 13\n",
      "LEAD: 24\n",
      "AVG: 14\n",
      "LEAD: 24\n",
      "AVG: 15\n",
      "LEAD: 24\n",
      "AVG: 16\n",
      "LEAD: 24\n",
      "AVG: 17\n",
      "LEAD: 24\n",
      "AVG: 18\n",
      "LEAD: 24\n",
      "AVG: 19\n",
      "LEAD: 24\n",
      "AVG: 20\n",
      "LEAD: 24\n",
      "AVG: 21\n",
      "LEAD: 24\n",
      "AVG: 22\n",
      "LEAD: 24\n",
      "AVG: 23\n",
      "LEAD: 24\n",
      "AVG: 24\n",
      "LEAD: 24\n",
      "AVG: 25\n",
      "LEAD: 24\n",
      "AVG: 26\n",
      "LEAD: 24\n",
      "AVG: 27\n",
      "LEAD: 24\n",
      "AVG: 28\n",
      "LEAD: 24\n",
      "AVG: 29\n",
      "LEAD: 24\n",
      "AVG: 30\n",
      "LEAD: 24\n",
      "AVG: 31\n",
      "LEAD: 25\n",
      "AVG: 2\n",
      "LEAD: 25\n",
      "AVG: 3\n",
      "LEAD: 25\n",
      "AVG: 4\n",
      "LEAD: 25\n",
      "AVG: 5\n",
      "LEAD: 25\n",
      "AVG: 6\n",
      "LEAD: 25\n",
      "AVG: 7\n",
      "LEAD: 25\n",
      "AVG: 8\n",
      "LEAD: 25\n",
      "AVG: 9\n",
      "LEAD: 25\n",
      "AVG: 10\n",
      "LEAD: 25\n",
      "AVG: 11\n",
      "LEAD: 25\n",
      "AVG: 12\n",
      "LEAD: 25\n",
      "AVG: 13\n",
      "LEAD: 25\n",
      "AVG: 14\n",
      "LEAD: 25\n",
      "AVG: 15\n",
      "LEAD: 25\n",
      "AVG: 16\n",
      "LEAD: 25\n",
      "AVG: 17\n",
      "LEAD: 25\n",
      "AVG: 18\n",
      "LEAD: 25\n",
      "AVG: 19\n",
      "LEAD: 25\n",
      "AVG: 20\n",
      "LEAD: 25\n",
      "AVG: 21\n",
      "LEAD: 25\n",
      "AVG: 22\n",
      "LEAD: 25\n",
      "AVG: 23\n",
      "LEAD: 25\n",
      "AVG: 24\n",
      "LEAD: 25\n",
      "AVG: 25\n",
      "LEAD: 25\n",
      "AVG: 26\n",
      "LEAD: 25\n",
      "AVG: 27\n",
      "LEAD: 25\n",
      "AVG: 28\n",
      "LEAD: 25\n",
      "AVG: 29\n",
      "LEAD: 25\n",
      "AVG: 30\n",
      "LEAD: 25\n",
      "AVG: 31\n",
      "LEAD: 26\n",
      "AVG: 2\n",
      "LEAD: 26\n",
      "AVG: 3\n",
      "LEAD: 26\n",
      "AVG: 4\n",
      "LEAD: 26\n",
      "AVG: 5\n",
      "LEAD: 26\n",
      "AVG: 6\n",
      "LEAD: 26\n",
      "AVG: 7\n",
      "LEAD: 26\n",
      "AVG: 8\n",
      "LEAD: 26\n",
      "AVG: 9\n",
      "LEAD: 26\n",
      "AVG: 10\n",
      "LEAD: 26\n",
      "AVG: 11\n",
      "LEAD: 26\n",
      "AVG: 12\n",
      "LEAD: 26\n",
      "AVG: 13\n",
      "LEAD: 26\n",
      "AVG: 14\n",
      "LEAD: 26\n",
      "AVG: 15\n",
      "LEAD: 26\n",
      "AVG: 16\n",
      "LEAD: 26\n",
      "AVG: 17\n",
      "LEAD: 26\n",
      "AVG: 18\n",
      "LEAD: 26\n",
      "AVG: 19\n",
      "LEAD: 26\n",
      "AVG: 20\n",
      "LEAD: 26\n",
      "AVG: 21\n",
      "LEAD: 26\n",
      "AVG: 22\n",
      "LEAD: 26\n",
      "AVG: 23\n",
      "LEAD: 26\n",
      "AVG: 24\n",
      "LEAD: 26\n",
      "AVG: 25\n",
      "LEAD: 26\n",
      "AVG: 26\n",
      "LEAD: 26\n",
      "AVG: 27\n",
      "LEAD: 26\n",
      "AVG: 28\n",
      "LEAD: 26\n",
      "AVG: 29\n",
      "LEAD: 26\n",
      "AVG: 30\n",
      "LEAD: 26\n",
      "AVG: 31\n",
      "LEAD: 27\n",
      "AVG: 2\n",
      "LEAD: 27\n",
      "AVG: 3\n",
      "LEAD: 27\n",
      "AVG: 4\n",
      "LEAD: 27\n",
      "AVG: 5\n",
      "LEAD: 27\n",
      "AVG: 6\n",
      "LEAD: 27\n",
      "AVG: 7\n",
      "LEAD: 27\n",
      "AVG: 8\n",
      "LEAD: 27\n",
      "AVG: 9\n",
      "LEAD: 27\n",
      "AVG: 10\n",
      "LEAD: 27\n",
      "AVG: 11\n",
      "LEAD: 27\n",
      "AVG: 12\n",
      "LEAD: 27\n",
      "AVG: 13\n",
      "LEAD: 27\n",
      "AVG: 14\n",
      "LEAD: 27\n",
      "AVG: 15\n",
      "LEAD: 27\n",
      "AVG: 16\n",
      "LEAD: 27\n",
      "AVG: 17\n",
      "LEAD: 27\n",
      "AVG: 18\n",
      "LEAD: 27\n",
      "AVG: 19\n",
      "LEAD: 27\n",
      "AVG: 20\n",
      "LEAD: 27\n",
      "AVG: 21\n",
      "LEAD: 27\n",
      "AVG: 22\n",
      "LEAD: 27\n",
      "AVG: 23\n",
      "LEAD: 27\n",
      "AVG: 24\n",
      "LEAD: 27\n",
      "AVG: 25\n",
      "LEAD: 27\n",
      "AVG: 26\n",
      "LEAD: 27\n",
      "AVG: 27\n",
      "LEAD: 27\n",
      "AVG: 28\n",
      "LEAD: 27\n",
      "AVG: 29\n",
      "LEAD: 27\n",
      "AVG: 30\n",
      "LEAD: 27\n",
      "AVG: 31\n",
      "LEAD: 28\n",
      "AVG: 2\n",
      "LEAD: 28\n",
      "AVG: 3\n",
      "LEAD: 28\n",
      "AVG: 4\n",
      "LEAD: 28\n",
      "AVG: 5\n",
      "LEAD: 28\n",
      "AVG: 6\n",
      "LEAD: 28\n",
      "AVG: 7\n",
      "LEAD: 28\n",
      "AVG: 8\n",
      "LEAD: 28\n",
      "AVG: 9\n",
      "LEAD: 28\n",
      "AVG: 10\n",
      "LEAD: 28\n",
      "AVG: 11\n",
      "LEAD: 28\n",
      "AVG: 12\n",
      "LEAD: 28\n",
      "AVG: 13\n",
      "LEAD: 28\n",
      "AVG: 14\n",
      "LEAD: 28\n",
      "AVG: 15\n",
      "LEAD: 28\n",
      "AVG: 16\n",
      "LEAD: 28\n",
      "AVG: 17\n",
      "LEAD: 28\n",
      "AVG: 18\n",
      "LEAD: 28\n",
      "AVG: 19\n",
      "LEAD: 28\n",
      "AVG: 20\n",
      "LEAD: 28\n",
      "AVG: 21\n",
      "LEAD: 28\n",
      "AVG: 22\n",
      "LEAD: 28\n",
      "AVG: 23\n",
      "LEAD: 28\n",
      "AVG: 24\n",
      "LEAD: 28\n",
      "AVG: 25\n",
      "LEAD: 28\n",
      "AVG: 26\n",
      "LEAD: 28\n",
      "AVG: 27\n",
      "LEAD: 28\n",
      "AVG: 28\n",
      "LEAD: 28\n",
      "AVG: 29\n",
      "LEAD: 28\n",
      "AVG: 30\n",
      "LEAD: 28\n",
      "AVG: 31\n",
      "LEAD: 29\n",
      "AVG: 2\n",
      "LEAD: 29\n",
      "AVG: 3\n",
      "LEAD: 29\n",
      "AVG: 4\n",
      "LEAD: 29\n",
      "AVG: 5\n",
      "LEAD: 29\n",
      "AVG: 6\n",
      "LEAD: 29\n",
      "AVG: 7\n",
      "LEAD: 29\n",
      "AVG: 8\n",
      "LEAD: 29\n",
      "AVG: 9\n",
      "LEAD: 29\n",
      "AVG: 10\n",
      "LEAD: 29\n",
      "AVG: 11\n",
      "LEAD: 29\n",
      "AVG: 12\n",
      "LEAD: 29\n",
      "AVG: 13\n",
      "LEAD: 29\n",
      "AVG: 14\n",
      "LEAD: 29\n",
      "AVG: 15\n",
      "LEAD: 29\n",
      "AVG: 16\n",
      "LEAD: 29\n",
      "AVG: 17\n",
      "LEAD: 29\n",
      "AVG: 18\n",
      "LEAD: 29\n",
      "AVG: 19\n",
      "LEAD: 29\n",
      "AVG: 20\n",
      "LEAD: 29\n",
      "AVG: 21\n",
      "LEAD: 29\n",
      "AVG: 22\n",
      "LEAD: 29\n",
      "AVG: 23\n",
      "LEAD: 29\n",
      "AVG: 24\n",
      "LEAD: 29\n",
      "AVG: 25\n",
      "LEAD: 29\n",
      "AVG: 26\n",
      "LEAD: 29\n",
      "AVG: 27\n",
      "LEAD: 29\n",
      "AVG: 28\n",
      "LEAD: 29\n",
      "AVG: 29\n",
      "LEAD: 29\n",
      "AVG: 30\n",
      "LEAD: 29\n",
      "AVG: 31\n",
      "LEAD: 30\n",
      "AVG: 2\n",
      "LEAD: 30\n",
      "AVG: 3\n",
      "LEAD: 30\n",
      "AVG: 4\n",
      "LEAD: 30\n",
      "AVG: 5\n",
      "LEAD: 30\n",
      "AVG: 6\n",
      "LEAD: 30\n",
      "AVG: 7\n",
      "LEAD: 30\n",
      "AVG: 8\n",
      "LEAD: 30\n",
      "AVG: 9\n",
      "LEAD: 30\n",
      "AVG: 10\n",
      "LEAD: 30\n",
      "AVG: 11\n",
      "LEAD: 30\n",
      "AVG: 12\n",
      "LEAD: 30\n",
      "AVG: 13\n",
      "LEAD: 30\n",
      "AVG: 14\n",
      "LEAD: 30\n",
      "AVG: 15\n",
      "LEAD: 30\n",
      "AVG: 16\n",
      "LEAD: 30\n",
      "AVG: 17\n",
      "LEAD: 30\n",
      "AVG: 18\n",
      "LEAD: 30\n",
      "AVG: 19\n",
      "LEAD: 30\n",
      "AVG: 20\n",
      "LEAD: 30\n",
      "AVG: 21\n",
      "LEAD: 30\n",
      "AVG: 22\n",
      "LEAD: 30\n",
      "AVG: 23\n",
      "LEAD: 30\n",
      "AVG: 24\n",
      "LEAD: 30\n",
      "AVG: 25\n",
      "LEAD: 30\n",
      "AVG: 26\n",
      "LEAD: 30\n",
      "AVG: 27\n",
      "LEAD: 30\n",
      "AVG: 28\n",
      "LEAD: 30\n",
      "AVG: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 09:22:13.391370: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 2s 4ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 4ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 2s 4ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 4ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 4ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 2s 5ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 4ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 4ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 2s 4ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 4ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 3ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 2s 6ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 2s 5ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 4ms/step\n",
      "saving\n",
      "LEAD: 30\n",
      "AVG: 30\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "360/360 [==============================] - 2s 4ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "360/360 [==============================] - 1s 3ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "360/360 [==============================] - 1s 3ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "360/360 [==============================] - 2s 4ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "360/360 [==============================] - 1s 3ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "360/360 [==============================] - 1s 3ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "360/360 [==============================] - 2s 4ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "360/360 [==============================] - 1s 3ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "360/360 [==============================] - 1s 3ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "360/360 [==============================] - 2s 4ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "360/360 [==============================] - 1s 3ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "360/360 [==============================] - 2s 5ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "360/360 [==============================] - 2s 4ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "360/360 [==============================] - 1s 3ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "360/360 [==============================] - 1s 3ms/step\n",
      "saving\n",
      "LEAD: 30\n",
      "AVG: 31\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "359/359 [==============================] - 2s 4ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "359/359 [==============================] - 1s 3ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "359/359 [==============================] - 1s 3ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "359/359 [==============================] - 1s 4ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "359/359 [==============================] - 1s 3ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "359/359 [==============================] - 1s 3ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "359/359 [==============================] - 1s 4ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "359/359 [==============================] - 1s 3ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "359/359 [==============================] - 1s 3ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "359/359 [==============================] - 1s 4ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "359/359 [==============================] - 1s 3ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "359/359 [==============================] - 1s 3ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "359/359 [==============================] - 1s 4ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "359/359 [==============================] - 1s 3ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "359/359 [==============================] - 1s 3ms/step\n",
      "saving\n"
     ]
    }
   ],
   "source": [
    "# model contribution fractions split by prediction sign\n",
    "\n",
    "for l in LEADS:\n",
    "    for a in AVGS:\n",
    "        print('LEAD: '+str(l)+'\\nAVG: '+str(a))\n",
    "        \n",
    "        ddir_check = '/glade/derecho/scratch/kjmayer/DATA/ENSOvsMJO/data/'\n",
    "        finame_check = 'model1_confcorrfracpred_bysign_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "        if not os.path.isfile(ddir_check+finame_check):\n",
    "            X1test, X2test, Ytest = get_testing(N_z500runmean=a,\n",
    "                                                LEAD=l)\n",
    "\n",
    "            INPUT_SHAPE1 = np.shape(X1test)[1:][0]\n",
    "            INPUT_SHAPE2 = np.shape(X2test)[1:][0]\n",
    "\n",
    "            model1_confcorr_fracpred = np.zeros(shape=(2,len(SEEDS)))\n",
    "            model2_confcorr_fracpred = np.zeros(shape=(2,len(SEEDS)))\n",
    "            model12_confcorr_fracpred = np.zeros(shape=(2,len(SEEDS)))\n",
    "\n",
    "            for s in SEEDS:\n",
    "                # ENSO MODEL\n",
    "                model1, input1 = build_model(s,\n",
    "                                             DROPOUT_RATE,\n",
    "                                             RIDGE1,\n",
    "                                             HIDDENS1,\n",
    "                                             INPUT_SHAPE1,\n",
    "                                             MODELNAME1)\n",
    "                # MJO MODEL\n",
    "                model2, input2 = build_model(s,\n",
    "                                             DROPOUT_RATE,\n",
    "                                             RIDGE2,\n",
    "                                             HIDDENS2,\n",
    "                                             INPUT_SHAPE2,\n",
    "                                             MODELNAME2)   \n",
    "                # COMBINE ENSO & MJO MODEL\n",
    "                model = fullmodel(model1, model2,\n",
    "                                  input1, input2,\n",
    "                                  s)\n",
    "\n",
    "                MODEL_FINAME = 'LEAD_'+str(l)+'_AVG_'+str(a)+'__0000'+str(s)+'.h5'\n",
    "                model.load_weights(MODEL_DIR+MODEL_FINAME)\n",
    "\n",
    "                model_rawpreds = model.predict((X1test,X2test))                \n",
    "\n",
    "                conf    = np.max(model_rawpreds,axis=-1)\n",
    "                predval = np.argmax(model_rawpreds,axis=-1)\n",
    "\n",
    "                # ------- confident predictions --------------------------------------------------------\n",
    "                per = 80\n",
    "                conf_thresh = np.percentile(conf,q=per)\n",
    "                # -------- confident [i_conf_predval] --------\n",
    "                i_conf_predval = np.where(conf > conf_thresh)[0]\n",
    "\n",
    "                # ----- model contribution: ------------------------------------------------------------\n",
    "                model1_rawpreds, model2_rawpreds = getoutputvecs(model,\n",
    "                                                                   model1,\n",
    "                                                                   model2,\n",
    "                                                                   X1test,\n",
    "                                                                   X2test)\n",
    "                # model X winning class (model X output * weight)\n",
    "                model1pred = np.argmax(model1_rawpreds,axis=1)\n",
    "                model2pred = np.argmax(model2_rawpreds,axis=1)\n",
    "\n",
    "                # --------------------------------------------------------------------------------------\n",
    "                # --------- confident & correct predictions contribution:-------------------------------\n",
    "                # --------------------------------------------------------------------------------------\n",
    "\n",
    "                # Where ENSO/MJO/final model (model 1/model 2/total) are correct\n",
    "                i_model1_confcorr = model1pred[i_conf_predval]==Ytest[i_conf_predval]\n",
    "                i_model2_confcorr = model2pred[i_conf_predval]==Ytest[i_conf_predval]\n",
    "                i_model_confcorr  = predval[i_conf_predval]==Ytest[i_conf_predval]\n",
    "\n",
    "\n",
    "                # terminology: \"win\" = modelX prediction is also (correct) full model prediction\n",
    "                # model X correct & model correct (model ~X not correct)\n",
    "                i_model1win = i_model1_confcorr & i_model_confcorr & ~i_model2_confcorr\n",
    "                i_model2win = i_model2_confcorr & i_model_confcorr & ~i_model1_confcorr\n",
    "                # model 1&2 correct & model correct\n",
    "                i_model12win = i_model1_confcorr & i_model2_confcorr & i_model_confcorr\n",
    "\n",
    "\n",
    "\n",
    "                # For correct predictions: model(X) values & predicted class when also full model prediction\n",
    "                n_model1win_predval_neg = np.shape(np.where(model1pred[i_conf_predval][i_model1win] == 0)[0])[0]\n",
    "                n_model1win_predval_pos = np.shape(np.where(model1pred[i_conf_predval][i_model1win] == 1)[0])[0]\n",
    "                # -\n",
    "                n_model2win_predval_neg = np.shape(np.where(model2pred[i_conf_predval][i_model2win] == 0)[0])[0]\n",
    "                n_model2win_predval_pos = np.shape(np.where(model2pred[i_conf_predval][i_model2win] == 1)[0])[0]\n",
    "                # -\n",
    "                n_model12win_predval_neg = np.shape(np.where(predval[i_conf_predval][i_model12win] == 0)[0])[0]\n",
    "                n_model12win_predval_pos = np.shape(np.where(predval[i_conf_predval][i_model12win] == 1)[0])[0]\n",
    "\n",
    "                if n_model1win_predval_neg + n_model1win_predval_pos + n_model2win_predval_neg + n_model2win_predval_pos + n_model12win_predval_neg + n_model12win_predval_pos == predval[i_conf_predval][i_model_confcorr].shape[0]:\n",
    "                    # print('SEED: '+str(s))\n",
    "                    # Percentage of model predictions correct due to just ENSO/MJO/ENSO&MJO:\n",
    "                    model1_confcorr_fracpred[0,s-1]  = (n_model1win_predval_neg/predval[i_conf_predval][i_model_confcorr].shape[0])\n",
    "                    model1_confcorr_fracpred[1,s-1]  = (n_model1win_predval_pos/predval[i_conf_predval][i_model_confcorr].shape[0])\n",
    "                    # -\n",
    "                    model2_confcorr_fracpred[0,s-1]  = (n_model2win_predval_neg/predval[i_conf_predval][i_model_confcorr].shape[0])\n",
    "                    model2_confcorr_fracpred[1,s-1]  = (n_model2win_predval_pos/predval[i_conf_predval][i_model_confcorr].shape[0])\n",
    "                    # -\n",
    "                    model12_confcorr_fracpred[0,s-1] = (n_model12win_predval_neg/predval[i_conf_predval][i_model_confcorr].shape[0])\n",
    "                    model12_confcorr_fracpred[1,s-1] = (n_model12win_predval_pos/predval[i_conf_predval][i_model_confcorr].shape[0])\n",
    "\n",
    "            if SAVE:\n",
    "                print('saving')\n",
    "                ddir_save = '/glade/derecho/scratch/kjmayer/DATA/ENSOvsMJO/data/'\n",
    "\n",
    "                finame_fracpred = 'model1_confcorrfracpred_bysign_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "                np.save(ddir_save+finame_fracpred, model1_confcorr_fracpred)\n",
    "                finame_fracpred = 'model2_confcorrfracpred_bysign_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "                np.save(ddir_save+finame_fracpred, model2_confcorr_fracpred)\n",
    "                finame_fracpred = 'model12_confcorrfracpred_bysign_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "                np.save(ddir_save+finame_fracpred, model12_confcorr_fracpred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011a9dbd-ebc2-4ce3-b8d3-5921bf806b75",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Old versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99e13375-62f6-466b-978d-b78d2781af53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model contribution fraction:\n",
    "# #    all predictions (not just correct)\n",
    "# #    confident predictions\n",
    "# #    correct & confident predictions\n",
    "\n",
    "# for l in LEADS:\n",
    "#     print('LEAD: '+str(l))\n",
    "#     for a in AVGS:\n",
    "#         print('AVG: '+str(a))\n",
    "        \n",
    "#         #check if files already exist:\n",
    "#         ddir_save = '/glade/work/kjmayer/research/catalyst/ENSOvsMJO/data/'\n",
    "#         finame_confvsacc = 'model12_allfracpredv2_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "#         if not os.path.isfile(ddir_save+finame_confvsacc):\n",
    "#             print('load testing data')\n",
    "#             X1test, X2test, Ytest = get_testing(N_z500runmean=a,\n",
    "#                                                 LEAD=l)\n",
    "\n",
    "#             INPUT_SHAPE1 = np.shape(X1test)[1:][0]\n",
    "#             INPUT_SHAPE2 = np.shape(X2test)[1:][0]\n",
    "\n",
    "#             model1_all_fracpred = np.zeros(shape=(len(SEEDS)))\n",
    "#             model2_all_fracpred = np.zeros(shape=(len(SEEDS)))\n",
    "#             model12_all_fracpred = np.zeros(shape=(len(SEEDS)))\n",
    "            \n",
    "#             model1_conf_fracpred = np.zeros(shape=(len(SEEDS)))\n",
    "#             model2_conf_fracpred = np.zeros(shape=(len(SEEDS)))\n",
    "#             model12_conf_fracpred = np.zeros(shape=(len(SEEDS)))\n",
    "            \n",
    "#             model1_confcorr_fracpred = np.zeros(shape=(len(SEEDS)))\n",
    "#             model2_confcorr_fracpred = np.zeros(shape=(len(SEEDS)))\n",
    "#             model12_confcorr_fracpred = np.zeros(shape=(len(SEEDS)))\n",
    "\n",
    "#             for s in SEEDS:\n",
    "#                 # ENSO MODEL\n",
    "#                 model1, input1 = build_model(s,\n",
    "#                                              DROPOUT_RATE,\n",
    "#                                              RIDGE1,\n",
    "#                                              HIDDENS1,\n",
    "#                                              INPUT_SHAPE1,\n",
    "#                                              MODELNAME1)\n",
    "#                 # MJO MODEL\n",
    "#                 model2, input2 = build_model(s,\n",
    "#                                              DROPOUT_RATE,\n",
    "#                                              RIDGE2,\n",
    "#                                              HIDDENS2,\n",
    "#                                              INPUT_SHAPE2,\n",
    "#                                              MODELNAME2)   \n",
    "#                 # COMBINE ENSO & MJO MODEL\n",
    "#                 model = fullmodel(model1, model2,\n",
    "#                                   input1, input2,\n",
    "#                                   s)\n",
    "\n",
    "#                 MODEL_FINAME = 'LEAD_'+str(l)+'_AVG_'+str(a)+'__0000'+str(s)+'.h5'\n",
    "#                 model.load_weights(MODEL_DIR+MODEL_FINAME)\n",
    "\n",
    "#                 model_rawpreds = model.predict((X1test,X2test))\n",
    "#                 conf    = np.max(model_rawpreds,axis=-1)\n",
    "#                 predval = np.argmax(model_rawpreds,axis=-1)\n",
    "\n",
    "                \n",
    "#                 # ------- confident predictions --------------------------------------------------------\n",
    "#                 per = 80\n",
    "#                 conf_thresh = np.percentile(conf,q=per)\n",
    "#                 # -------- confident [i_conf_predval] --------\n",
    "#                 i_conf_predval = np.where(conf > conf_thresh)[0]\n",
    "                \n",
    "\n",
    "#                 # ----- model contribution: ------------------------------------------------------------\n",
    "#                 model1_rawpreds, model2_rawpreds = getoutputvecs(model,\n",
    "#                                                                  model1,\n",
    "#                                                                  model2,\n",
    "#                                                                  X1test,\n",
    "#                                                                  X2test)\n",
    "#                 # model X winning class (model X output * weight)\n",
    "#                 model1pred = np.argmax(model1_rawpreds,axis=1)\n",
    "#                 model2pred = np.argmax(model2_rawpreds,axis=1)\n",
    "\n",
    "                \n",
    "                \n",
    "#                 # ---------- all predictions contribution:\n",
    "#                 i_model1_samefinalpred = model1pred==predval\n",
    "#                 i_model2_samefinalpred = model2pred==predval\n",
    "                \n",
    "#                 # terminology: \"win\" = modelX prediction is also full model prediction\n",
    "#                 # model X same as final prediction & model ~X does not have that prediction\n",
    "#                 i_model1win = i_model1_samefinalpred & ~i_model2_samefinalpred\n",
    "#                 i_model2win = i_model2_samefinalpred & ~i_model1_samefinalpred\n",
    "#                 # model 1&2 have same final prediction\n",
    "#                 i_model12win = i_model1_samefinalpred & i_model2_samefinalpred\n",
    "                \n",
    "                \n",
    "#                 # number of predictions of model(X) predicted class that is also full model prediction\n",
    "#                 n_model1win_predval = model1pred[i_model1win].shape[0]\n",
    "#                 n_model2win_predval = model2pred[i_model2win].shape[0]\n",
    "#                 n_model12win_predval = predval[i_model12win].shape[0]\n",
    "                \n",
    "#                 # these shapes should be equal (True), assuming ~i_model1corr & ~i_model2corr & i_modelcorr doesnt happen\n",
    "#                 if predval.shape[0] == n_model1win_predval + n_model2win_predval + n_model12win_predval:\n",
    "#                     print('SEED: '+str(s))\n",
    "#                     # Percentage of model predictions correct due to just ENSO/MJO/ENSO&MJO:\n",
    "#                     model1_all_fracpred[s-1]  = (n_model1win_predval/predval.shape[0])\n",
    "#                     model2_all_fracpred[s-1]  = (n_model2win_predval/predval.shape[0])\n",
    "#                     model12_all_fracpred[s-1] = (n_model12win_predval/predval.shape[0]) \n",
    "                    \n",
    "                    \n",
    "                \n",
    "#                 # --------- confident predictions contribution:\n",
    "#                 i_model1_samefinalconfpred = model1pred[i_conf_predval]==predval[i_conf_predval]\n",
    "#                 i_model2_samefinalconfpred = model2pred[i_conf_predval]==predval[i_conf_predval]\n",
    "                \n",
    "#                 # terminology: \"win\" = modelX prediction is also full model prediction\n",
    "#                 # model X same as final prediction & model ~X does not have that prediction\n",
    "#                 i_model1win = i_model1_samefinalconfpred & ~i_model2_samefinalconfpred\n",
    "#                 i_model2win = i_model2_samefinalconfpred & ~i_model1_samefinalconfpred\n",
    "#                 # model 1&2 have same final prediction\n",
    "#                 i_model12win = i_model1_samefinalconfpred & i_model2_samefinalconfpred\n",
    "                \n",
    "                \n",
    "#                 # number of predictions of model(X) predicted class that is also full model prediction\n",
    "#                 n_model1win_predval = model1pred[i_conf_predval][i_model1win].shape[0]\n",
    "#                 n_model2win_predval = model2pred[i_conf_predval][i_model2win].shape[0]\n",
    "#                 n_model12win_predval = predval[i_conf_predval][i_model12win].shape[0]\n",
    "\n",
    "                \n",
    "#                 # these shapes should be equal (True), assuming ~i_model1corr & ~i_model2corr & i_modelcorr doesnt happen\n",
    "#                 if predval[i_conf_predval].shape[0] == n_model1win_predval + n_model2win_predval + n_model12win_predval:\n",
    "#                     print('SEED: '+str(s))\n",
    "#                     # Percentage of model predictions correct due to just ENSO/MJO/ENSO&MJO:\n",
    "#                     model1_conf_fracpred[s-1]  = (n_model1win_predval/predval[i_conf_predval].shape[0])\n",
    "#                     model2_conf_fracpred[s-1]  = (n_model2win_predval/predval[i_conf_predval].shape[0])\n",
    "#                     model12_conf_fracpred[s-1] = (n_model12win_predval/predval[i_conf_predval].shape[0]) \n",
    "                \n",
    "                \n",
    "                \n",
    "#                 # --------- confident & correct predictions contribution:\n",
    "#                 # Where ENSO/MJO/final model (model 1/model 2/total) are correct\n",
    "#                 i_model1_confcorr = model1pred[i_conf_predval]==Ytest[i_conf_predval]\n",
    "#                 i_model2_confcorr = model2pred[i_conf_predval]==Ytest[i_conf_predval]\n",
    "#                 i_model_confcorr  = predval[i_conf_predval]==Ytest[i_conf_predval]\n",
    "\n",
    "#                 # terminology: \"win\" = modelX prediction is also (correct) full model prediction\n",
    "#                 # model X correct & model correct (model ~X not correct)\n",
    "#                 i_model1win = i_model1_confcorr & i_model_confcorr & ~i_model2_confcorr\n",
    "#                 i_model2win = i_model2_confcorr & i_model_confcorr & ~i_model1_confcorr\n",
    "#                 # model 1&2 correct & model correct\n",
    "#                 i_model12win = i_model1_confcorr & i_model2_confcorr & i_model_confcorr\n",
    "\n",
    "#                 # For correct predictions: model(X) values & predicted class when also full model prediction\n",
    "#                 n_model1win_predval = model1pred[i_conf_predval][i_model1win].shape[0]\n",
    "#                 n_model2win_predval = model2pred[i_conf_predval][i_model2win].shape[0]\n",
    "#                 n_model12win_predval = predval[i_conf_predval][i_model12win].shape[0]\n",
    "                \n",
    "                \n",
    "#                 # these shapes should be equal (True), assuming ~i_model1corr & ~i_model2corr & i_modelcorr doesnt happen\n",
    "#                 if predval[i_conf_predval][i_model_confcorr].shape[0] == n_model1win_predval + n_model2win_predval + n_model12win_predval:\n",
    "#                     print('SEED: '+str(s))\n",
    "#                     # Percentage of model predictions correct due to just ENSO/MJO/ENSO&MJO:\n",
    "#                     model1_confcorr_fracpred[s-1]  = (n_model1win_predval/predval[i_conf_predval][i_model_confcorr].shape[0])\n",
    "#                     model2_confcorr_fracpred[s-1]  = (n_model2win_predval/predval[i_conf_predval][i_model_confcorr].shape[0])\n",
    "#                     model12_confcorr_fracpred[s-1] = (n_model12win_predval/predval[i_conf_predval][i_model_confcorr].shape[0])    \n",
    "            \n",
    "            \n",
    "#             # ------------------------------------------------------------------------------------------\n",
    "#             if SAVE: \n",
    "#                 print('saving')\n",
    "#                 ddir_save = '/glade/work/kjmayer/research/catalyst/ENSOvsMJO/data/'\n",
    "\n",
    "#                 finame_fracpred = 'model1_allfracpredv2_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "#                 np.save(ddir_save+finame_fracpred, model1_all_fracpred)\n",
    "#                 finame_fracpred = 'model2_allfracpredv2_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "#                 np.save(ddir_save+finame_fracpred, model2_all_fracpred)\n",
    "#                 finame_fracpred = 'model12_allfracpredv2_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "#                 np.save(ddir_save+finame_fracpred, model12_all_fracpred)\n",
    "                \n",
    "#                 finame_fracpred = 'model1_conffracpredv2_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "#                 np.save(ddir_save+finame_fracpred, model1_conf_fracpred)\n",
    "#                 finame_fracpred = 'model2_conffracpredv2_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "#                 np.save(ddir_save+finame_fracpred, model2_conf_fracpred)\n",
    "#                 finame_fracpred = 'model12_conffracpredv2_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "#                 np.save(ddir_save+finame_fracpred, model12_conf_fracpred)\n",
    "                \n",
    "#                 finame_fracpred = 'model1_confcorrfracpredv2_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "#                 np.save(ddir_save+finame_fracpred, model1_confcorr_fracpred)\n",
    "#                 finame_fracpred = 'model2_confcorrfracpredv2_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "#                 np.save(ddir_save+finame_fracpred, model2_confcorr_fracpred)\n",
    "#                 finame_fracpred = 'model12_confcorrfracpredv2_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "#                 np.save(ddir_save+finame_fracpred, model12_confcorr_fracpred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2343190-3272-4fd9-9450-54d6301fcb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model raw predictions\n",
    "# # confidence vs accuracy\n",
    "# # model contribution fraction (correct)\n",
    "# for l in LEADS:\n",
    "#     print('LEAD: '+str(l))\n",
    "#     for a in AVGS:\n",
    "#         print('AVG: '+str(a))\n",
    "        \n",
    "#         #check if files already exist:\n",
    "#         ddir_save = '/glade/work/kjmayer/research/catalyst/ENSOvsMJO/data/'\n",
    "#         finame_confvsacc = 'confvsacc_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "#         if not os.path.isfile(ddir_save+finame_confvsacc):\n",
    "#             print('load testing data')\n",
    "#             X1test, X2test, Ytest = get_testing(N_z500runmean=a,\n",
    "#                                                 LEAD=l)\n",
    "\n",
    "#             INPUT_SHAPE1 = np.shape(X1test)[1:][0]\n",
    "#             INPUT_SHAPE2 = np.shape(X2test)[1:][0]\n",
    "\n",
    "#             confvsacc = np.zeros(shape=(len(SEEDS),100))\n",
    "\n",
    "#             model1_rawpreds = np.zeros(shape=(len(SEEDS),np.shape(X1test)[0],2))\n",
    "#             model2_rawpreds = np.zeros(shape=(len(SEEDS),np.shape(X1test)[0],2))\n",
    "#             model_rawpreds = np.zeros(shape=(len(SEEDS),np.shape(X1test)[0],2))\n",
    "\n",
    "#             model1_fracpred = np.zeros(shape=(len(SEEDS)))\n",
    "#             model2_fracpred = np.zeros(shape=(len(SEEDS)))\n",
    "#             model12_fracpred = np.zeros(shape=(len(SEEDS)))\n",
    "\n",
    "#             for s in SEEDS:\n",
    "#                 # ENSO MODEL\n",
    "#                 model1, input1 = build_model(s,\n",
    "#                                              DROPOUT_RATE,\n",
    "#                                              RIDGE1,\n",
    "#                                              HIDDENS1,\n",
    "#                                              INPUT_SHAPE1,\n",
    "#                                              MODELNAME1)\n",
    "#                 # MJO MODEL\n",
    "#                 model2, input2 = build_model(s,\n",
    "#                                              DROPOUT_RATE,\n",
    "#                                              RIDGE2,\n",
    "#                                              HIDDENS2,\n",
    "#                                              INPUT_SHAPE2,\n",
    "#                                              MODELNAME2)   \n",
    "#                 # COMBINE ENSO & MJO MODEL\n",
    "#                 model = fullmodel(model1, model2,\n",
    "#                                   input1, input2,\n",
    "#                                   s)\n",
    "\n",
    "#                 MODEL_FINAME = 'LEAD_'+str(l)+'_AVG_'+str(a)+'__0000'+str(s)+'.h5'\n",
    "#                 model.load_weights(MODEL_DIR+MODEL_FINAME)\n",
    "\n",
    "#                 model_rawpreds[s-1] = model.predict((X1test,X2test))\n",
    "#                 conf    = np.max(model_rawpreds[s-1],axis=-1)\n",
    "#                 predval = np.argmax(model_rawpreds[s-1],axis=-1)\n",
    "\n",
    "#                 # ----- confidence vs accuracy for all seeds:\n",
    "#                 confvsacc[s-1], _, _ = confvacc(confval = conf,\n",
    "#                                               predval = predval,\n",
    "#                                               Ytest   = Ytest)\n",
    "\n",
    "#                 # ----- model contribution:\n",
    "#                 model1_rawpreds[s-1], model2_rawpreds[s-1] = getoutputvecs(model,\n",
    "#                                                                        model1,\n",
    "#                                                                        model2,\n",
    "#                                                                        X1test,\n",
    "#                                                                        X2test)\n",
    "#                 # model X winning class (model X output * weight)\n",
    "#                 model1pred = np.argmax(model1_rawpreds[s-1],axis=1)\n",
    "#                 model2pred = np.argmax(model2_rawpreds[s-1],axis=1)\n",
    "\n",
    "#                 # Where ENSO/MJO/final model (model 1/model 2/total) are correct\n",
    "#                 i_model1corr = model1pred==Ytest\n",
    "#                 i_model2corr = model2pred==Ytest\n",
    "#                 i_modelcorr  = predval==Ytest\n",
    "\n",
    "#                 # terminology: \"win\" = modelX prediction is also (correct) full model prediction\n",
    "#                 # model X correct & model correct (model ~X not correct)\n",
    "#                 i_model1win = i_model1corr & i_modelcorr & ~i_model2corr\n",
    "#                 i_model2win = i_model2corr & i_modelcorr & ~i_model1corr\n",
    "#                 # model 1&2 correct & model correct\n",
    "#                 i_model12win = i_model1corr & i_model2corr & i_modelcorr\n",
    "\n",
    "#                 # For correct predictions: model(X) values & predicted class when also full model prediction\n",
    "#                 model1win_contribution = model1_rawpreds[s-1][i_model1win]\n",
    "#                 model1win_predval = model1pred[i_model1win]\n",
    "\n",
    "#                 model2win_contribution = model2_rawpreds[s-1][i_model2win]\n",
    "#                 model2win_predval = model2pred[i_model2win]\n",
    "\n",
    "#                 model12win_predval = model_rawpreds[s-1][i_model12win]\n",
    "\n",
    "#                 # these shapes should be equal (True), assuming ~i_model1corr & ~i_model2corr & i_modelcorr doesnt happen\n",
    "#                 if model_rawpreds[s-1][i_modelcorr].shape[0] == model1win_predval.shape[0] + model2win_predval.shape[0] + model12win_predval.shape[0]:\n",
    "#                     print('SEED: '+str(s))\n",
    "#                     # Percentage of model predictions correct due to just ENSO/MJO/ENSO&MJO:\n",
    "#                     model1_fracpred[s-1]  = (model1win_predval.shape[0]/model_rawpreds[s-1][i_modelcorr].shape[0])\n",
    "#                     model2_fracpred[s-1]  = (model2win_predval.shape[0]/model_rawpreds[s-1][i_modelcorr].shape[0])\n",
    "#                     model12_fracpred[s-1] = (model12win_predval.shape[0]/model_rawpreds[s-1][i_modelcorr].shape[0])        \n",
    "\n",
    "#             if SAVE:\n",
    "#                 print('saving')\n",
    "#                 ddir_save = '/glade/work/kjmayer/research/catalyst/ENSOvsMJO/data/'\n",
    "                \n",
    "#                 finame_confvsacc = 'confvsacc_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "#                 np.save(ddir_save+finame_confvsacc, confvsacc)\n",
    "\n",
    "#                 finame_rawpred = 'model1_rawpred_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "#                 np.save(ddir_save+finame_rawpred, model1_rawpreds)\n",
    "#                 finame_rawpred = 'model2_rawpred_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "#                 np.save(ddir_save+finame_rawpred, model2_rawpreds)\n",
    "#                 finame_rawpred = 'model_rawpred_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "#                 np.save(ddir_save+finame_rawpred, model_rawpreds)\n",
    "\n",
    "#                 finame_fracpred = 'model1_fracpred_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "#                 np.save(ddir_save+finame_fracpred, model1_fracpred)\n",
    "#                 finame_fracpred = 'model2_fracpred_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "#                 np.save(ddir_save+finame_fracpred, model2_fracpred)\n",
    "#                 finame_fracpred = 'model12_fracpred_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "#                 np.save(ddir_save+finame_fracpred, model12_fracpred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2-env-v2",
   "language": "python",
   "name": "tf2-env-v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
