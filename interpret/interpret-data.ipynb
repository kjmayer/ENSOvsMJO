{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9a6521f-0052-4657-8336-00fb21e8409a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Interpretability Script!\n",
    "This script is to explore the relative contributions of the MJO & ENSO (indices) to prediction of z500 in the North Pacific (part of the PNA) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be49fae-2aa3-4bf9-9d4c-f12d003662ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prep for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b66c4fa-5299-467a-809d-cb3fc8d30589",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-08 14:40:26.620628: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-08 14:40:26.921340: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random \n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('/glade/work/kjmayer/research/catalyst/ENSOvsMJO/utils/')\n",
    "# sys.path.append('/glade/u/home/wchapman/ENSOvsMJO/utils/')\n",
    "from exp_hp import get_hp\n",
    "from trainGordon_utils import subset, build_model, fullmodel, scheduler, plot_results, adjust_spines\n",
    "from dataprep_utils import get_testing\n",
    "sys.path.append('/glade/work/kjmayer/research/catalyst/ENSOvsMJO/interpret/')\n",
    "# sys.path.append('/glade/u/home/wchapman/ENSOvsMJO/interpret/')\n",
    "from Gordon_interp import getoutputvecs, confvacc, iconfcorr\n",
    "\n",
    "\n",
    "# import importlib\n",
    "# importlib.reload(sys.modules[\"Gordon_interp\"])\n",
    "# from Gordon_interp import getoutputvecs, confvacc, iconfcorr\n",
    "# importlib.reload(sys.modules[\"trainGordon_utils\"])\n",
    "# from trainGordon_utils import subset, build_model, fullmodel, scheduler, plot_results\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('text',usetex=True)\n",
    "plt.rcParams['font.family']='sans-serif'\n",
    "plt.rcParams['font.sans-serif']=['Verdana']\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "def adjust_spines(ax, spines):\n",
    "    for loc, spine in ax.spines.items():\n",
    "        if loc in spines:\n",
    "            spine.set_position(('outward', 5))\n",
    "        else:\n",
    "            spine.set_color('none')\n",
    "    if 'left' in spines:\n",
    "        ax.yaxis.set_ticks_position('left')\n",
    "    else:\n",
    "        ax.yaxis.set_ticks([])\n",
    "    if 'bottom' in spines:\n",
    "        ax.xaxis.set_ticks_position('bottom')\n",
    "    else:\n",
    "            ax.xaxis.set_ticks([])\n",
    "mpl.rcParams['figure.facecolor'] = 'white'\n",
    "mpl.rcParams['figure.dpi'] = 150\n",
    "dpiFig = 300."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb4fdd3-934d-4eea-b75f-64c18a60aa25",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09f14733-e325-454d-9f75-245f84158ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = '/glade/scratch/wchapman/ENSOmjo_ML_models/saved_models/'\n",
    "EXP_NAME = 'default'\n",
    "hps = get_hp(EXP_NAME)\n",
    "# variables:\n",
    "DROPOUT_RATE = hps['DROPOUT_RATE']\n",
    "\n",
    "MODELNAME1 = 'ENSO'\n",
    "RIDGE1 = hps['RIDGE1']\n",
    "HIDDENS1 = hps['HIDDENS1']\n",
    "\n",
    "MODELNAME2 = 'MJO'\n",
    "RIDGE2 = hps['RIDGE2']\n",
    "HIDDENS2 = hps['HIDDENS2']\n",
    "\n",
    "BATCH_SIZE = hps['BATCH_SIZE']\n",
    "N_EPOCHS = 10000\n",
    "PATIENCE = hps['PATIENCE'] # number of epochs of no \"improvement\" before training is stopped\n",
    "LR = hps['LR'] # learning rate\n",
    "\n",
    "\n",
    "LEADS = np.arange(7,31)\n",
    "AVGS = np.arange(7,32)\n",
    "SEEDS = np.arange(1,6)\n",
    "\n",
    "SAVE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2343190-3272-4fd9-9450-54d6301fcb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEAD: 7\n",
      "AVG: 7\n",
      "load testing data\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-08 14:43:09.628197: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362/362 [==============================] - 1s 2ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "362/362 [==============================] - 1s 1ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "362/362 [==============================] - 1s 1ms/step\n",
      "SEED: 1\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "362/362 [==============================] - 1s 2ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "362/362 [==============================] - 1s 1ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "362/362 [==============================] - 1s 2ms/step\n",
      "SEED: 2\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "362/362 [==============================] - 1s 2ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "362/362 [==============================] - 1s 1ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "362/362 [==============================] - 1s 1ms/step\n",
      "SEED: 3\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "362/362 [==============================] - 1s 2ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "362/362 [==============================] - 1s 1ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "362/362 [==============================] - 1s 1ms/step\n",
      "SEED: 4\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "362/362 [==============================] - 1s 2ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "362/362 [==============================] - 1s 1ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "362/362 [==============================] - 1s 1ms/step\n",
      "SEED: 5\n",
      "saving\n",
      "AVG: 8\n",
      "load testing data\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 2ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 1ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 1ms/step\n",
      "SEED: 1\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 2ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 1ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 1ms/step\n",
      "SEED: 2\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 2ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 1ms/step\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "361/361 [==============================] - 1s 1ms/step\n",
      "SEED: 3\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      " 27/361 [=>............................] - ETA: 0s "
     ]
    }
   ],
   "source": [
    "for l in LEADS:\n",
    "    print('LEAD: '+str(l))\n",
    "    for a in AVGS:\n",
    "        print('AVG: '+str(a))\n",
    "        print('load testing data')\n",
    "        X1test, X2test, Ytest = get_testing(N_z500runmean=a,\n",
    "                                            LEAD=l)\n",
    "                \n",
    "        INPUT_SHAPE1 = np.shape(X1test)[1:][0]\n",
    "        INPUT_SHAPE2 = np.shape(X2test)[1:][0]\n",
    "        \n",
    "        confvsacc = np.zeros(shape=(len(SEEDS),100))\n",
    "        \n",
    "        model1_rawpreds = np.zeros(shape=(len(SEEDS),np.shape(X1test)[0],2))\n",
    "        model2_rawpreds = np.zeros(shape=(len(SEEDS),np.shape(X1test)[0],2))\n",
    "        model_rawpreds = np.zeros(shape=(len(SEEDS),np.shape(X1test)[0],2))\n",
    "        \n",
    "        model1_fracpred = np.zeros(shape=(len(SEEDS)))\n",
    "        model2_fracpred = np.zeros(shape=(len(SEEDS)))\n",
    "        model12_fracpred = np.zeros(shape=(len(SEEDS)))\n",
    "        \n",
    "        for s in SEEDS:\n",
    "            # ENSO MODEL\n",
    "            model1, input1 = build_model(s,\n",
    "                                         DROPOUT_RATE,\n",
    "                                         RIDGE1,\n",
    "                                         HIDDENS1,\n",
    "                                         INPUT_SHAPE1,\n",
    "                                         MODELNAME1)\n",
    "            # MJO MODEL\n",
    "            model2, input2 = build_model(s,\n",
    "                                         DROPOUT_RATE,\n",
    "                                         RIDGE2,\n",
    "                                         HIDDENS2,\n",
    "                                         INPUT_SHAPE2,\n",
    "                                         MODELNAME2)   \n",
    "            # COMBINE ENSO & MJO MODEL\n",
    "            model = fullmodel(model1, model2,\n",
    "                              input1, input2,\n",
    "                              s)\n",
    "            \n",
    "            MODEL_FINAME = 'LEAD_'+str(l)+'_AVG_'+str(a)+'__0000'+str(s)+'.h5'\n",
    "            model.load_weights(MODEL_DIR+MODEL_FINAME)\n",
    "            \n",
    "            model_rawpreds[s-1] = model.predict((X1test,X2test))\n",
    "            conf    = np.max(model_rawpreds[s-1],axis=-1)\n",
    "            predval = np.argmax(model_rawpreds[s-1],axis=-1)\n",
    "            \n",
    "            # ----- confidence vs accuracy for all seeds:\n",
    "            confvsacc[s-1], _, _ = confvacc(confval = conf,\n",
    "                                          predval = predval,\n",
    "                                          Ytest   = Ytest)\n",
    "            \n",
    "            # ----- model contribution:\n",
    "            model1_rawpreds[s-1], model2_rawpreds[s-1] = getoutputvecs(model,\n",
    "                                                                   model1,\n",
    "                                                                   model2,\n",
    "                                                                   X1test,\n",
    "                                                                   X2test)\n",
    "            # model X winning class (model X output * weight)\n",
    "            model1pred = np.argmax(model1_rawpreds[s-1],axis=1)\n",
    "            model2pred = np.argmax(model2_rawpreds[s-1],axis=1)\n",
    "        \n",
    "            # Where ENSO/MJO/final model (model 1/model 2/total) are correct\n",
    "            i_model1corr = model1pred==Ytest\n",
    "            i_model2corr = model2pred==Ytest\n",
    "            i_modelcorr  = predval==Ytest\n",
    "        \n",
    "            # terminology: \"win\" = modelX prediction is also (correct) full model prediction\n",
    "            # model X correct & model correct (model ~X not correct)\n",
    "            i_model1win = i_model1corr & i_modelcorr & ~i_model2corr\n",
    "            i_model2win = i_model2corr & i_modelcorr & ~i_model1corr\n",
    "            # model 1&2 correct & model correct\n",
    "            i_model12win = i_model1corr & i_model2corr & i_modelcorr\n",
    "        \n",
    "            # For correct predictions: model(X) values & predicted class when also full model prediction\n",
    "            model1win_contribution = model1_rawpreds[s-1][i_model1win]\n",
    "            model1win_predval = model1pred[i_model1win]\n",
    "\n",
    "            model2win_contribution = model2_rawpreds[s-1][i_model2win]\n",
    "            model2win_predval = model2pred[i_model2win]\n",
    "\n",
    "            model12win_predval = model_rawpreds[s-1][i_model12win]\n",
    "            \n",
    "            # these shapes should be equal (True), assuming ~i_model1corr & ~i_model2corr & i_modelcorr doesnt happen\n",
    "            if model_rawpreds[s-1][i_modelcorr].shape[0] == model1win_predval.shape[0] + model2win_predval.shape[0] + model12win_predval.shape[0]:\n",
    "                print('SEED: '+str(s))\n",
    "                # Percentage of model predictions correct due to just ENSO/MJO/ENSO&MJO:\n",
    "                model1_fracpred[s-1]  = (model1win_predval.shape[0]/model_rawpreds[s-1][i_modelcorr].shape[0])\n",
    "                model2_fracpred[s-1]  = (model2win_predval.shape[0]/model_rawpreds[s-1][i_modelcorr].shape[0])\n",
    "                model12_fracpred[s-1] = (model12win_predval.shape[0]/model_rawpreds[s-1][i_modelcorr].shape[0])        \n",
    "        \n",
    "        if SAVE:\n",
    "            print('saving')\n",
    "            ddir_save = '/glade/work/kjmayer/research/catalyst/ENSOvsMJO/data/'\n",
    "            \n",
    "            finame_confvsacc = 'confvsacc_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "            np.save(ddir_save+finame_confvsacc, confvsacc)\n",
    "            \n",
    "            finame_rawpred = 'model1_rawpred_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "            np.save(ddir_save+finame_rawpred, model1_rawpreds)\n",
    "            finame_rawpred = 'model2_rawpred_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "            np.save(ddir_save+finame_rawpred, model2_rawpreds)\n",
    "            finame_rawpred = 'model_rawpred_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "            np.save(ddir_save+finame_rawpred, model_rawpreds)\n",
    "            \n",
    "            finame_fracpred = 'model1_fracpred_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "            np.save(ddir_save+finame_fracpred, model1_fracpred)\n",
    "            finame_fracpred = 'model2_fracpred_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "            np.save(ddir_save+finame_fracpred, model2_fracpred)\n",
    "            finame_fracpred = 'model12_fracpred_LEAD_'+str(l)+'_AVG_'+str(a)+'__00001-00005.npy'\n",
    "            np.save(ddir_save+finame_fracpred, model12_fracpred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e13375-62f6-466b-978d-b78d2781af53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2-env-v2",
   "language": "python",
   "name": "tf2-env-v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
