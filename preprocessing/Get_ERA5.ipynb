{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12bffb4a-021a-4926-ad06-4722c6ceb79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cbf4661-8b20-46b0-bba4-de1c2a573fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client does not exist yet\n"
     ]
    }
   ],
   "source": [
    "if 'client' in locals():\n",
    "    client.shutdown()\n",
    "    print('...shutdown client...')\n",
    "else:\n",
    "    print('client does not exist yet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b96dae49-9bf2-41e0-bb66-94cef1e86756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import Client\n",
    "from ncar_jobqueue import NCARCluster\n",
    "\n",
    "cluster = NCARCluster(project='P54048000',walltime='11:00:00')\n",
    "cluster.scale(40)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d27ff633-b0ed-4050-a039-5e0da8bebb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17897\n"
     ]
    }
   ],
   "source": [
    "def flatten_list(input_list):\n",
    "    flattened_list = []\n",
    "    for item in input_list:\n",
    "        if isinstance(item, list):\n",
    "            flattened_list.extend(flatten_list(item))\n",
    "        else:\n",
    "            flattened_list.append(item)\n",
    "    return flattened_list\n",
    "\n",
    "FNS_all_z = []\n",
    "for yryr in range(1974,2023):\n",
    "    for momo in range(1,13):\n",
    "        FNS = sorted(glob.glob('/glade/collections/rda/data/ds633.0/e5.oper.an.pl/'+str(yryr)+str(momo).zfill(2)+'/*_z.*.nc'))\n",
    "        FNS_all_z.append(FNS)\n",
    "FNS_all_z = flatten_list(FNS_all_z)\n",
    "\n",
    "print(len(FNS_all_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7078706-29be-41ac-824f-19279ef26ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirout = '/glade/scratch/wchapman/ERA5_uvolr/'\n",
    "for ee,fnfn in enumerate(FNS_all_z):\n",
    "    file_out_name = dirout + fnfn[:-16].split('/')[-1]+'.nc'\n",
    "    print(file_out_name)\n",
    "    if os.path.exists(file_out_name):\n",
    "        print(f\"File '{file_out_name}' already exists. Continuing to the next file...\")\n",
    "        continue\n",
    "    else: \n",
    "        DS = xr.open_dataset(fnfn, chunks={'time': 'auto'})\n",
    "        DS = DS.sel(level=[500])\n",
    "        DS =  DS.mean('time').load()\n",
    "        dtdt=fnfn[:-16].split('.')[-1]\n",
    "        dtrang = pd.date_range(start=dtdt[0:4]+'-'+dtdt[4:6]+'-'+dtdt[6:8],end='2024-01-01')[0]\n",
    "        DS = DS.expand_dims(time=[dtrang]).drop('utc_date')\n",
    "        DS.to_netcdf(file_out_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69264303-abee-434a-9c43-d570962f7c4f",
   "metadata": {},
   "source": [
    "## Regrid to the CAM Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f655874-87d8-4800-9bf9-eafc47193efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "FNSall = sorted(glob.glob('/glade/scratch/wchapman/ERA5_uvolr/*128_129_z*.nc'))\n",
    "#grab an example file to get the grid: \n",
    "DScamgrid = xr.open_dataset('/glade/campaign/cisl/aiml/wchapman/CAM_runs/f.e21.DAcompset.f09_d025_free_MJO_1982/atm/hist/f.e21.DAcompset.f09_d025_free_MJO_1982.cam.h0.1982-02.nc')\n",
    "DScamgrid\n",
    "\n",
    "#make regridder structure:\n",
    "ds_out = xr.Dataset(\n",
    "    {\n",
    "        \"lat\": ([\"lat\"], np.array(DScamgrid.lat)),\n",
    "        \"lon\": ([\"lon\"], np.array(DScamgrid.lon)),\n",
    "    }\n",
    ")\n",
    "\n",
    "#gather dates\n",
    "fnunique = np.unique([fnfn.split('.')[-2] for fnfn in FNSall])\n",
    "print('starting loop')\n",
    "for ee,dtdt in enumerate(fnunique):\n",
    "    if ee%50==0:\n",
    "        print(f'loop {ee} of {len(fnunique)}')\n",
    "    FNSdtdt = sorted(glob.glob('/glade/scratch/wchapman/ERA5_uvolr/*128_129_z*'+dtdt+'*.nc'))\n",
    "    \n",
    "    if len(FNSdtdt) !=1:\n",
    "        print('stopped at:', dtdt)\n",
    "        break\n",
    "        \n",
    "    for indfiles in FNSdtdt: \n",
    "        #do the rest of my operations\n",
    "            \n",
    "        outfile = '/glade/scratch/wchapman/ERA5_uvolr/1deg/'+indfiles.split('/')[-1][:-2]+'1deg.nc'\n",
    "        if os.path.exists(outfile):\n",
    "            # File exists, continue with the loop iteration\n",
    "            print(f\"File '{outfile}' exists. Continuing with the loop iteration...\")\n",
    "            # Additional actions for the existing file...\n",
    "            continue  # Continue to the next iteration\n",
    "            \n",
    "        DSall = xr.open_dataset(indfiles)\n",
    "        # ##build regridder method: \n",
    "        if ee == 0:\n",
    "            print('...rebuilding weight file...')\n",
    "            regridder_save_weights = xe.Regridder(DSall, ds_out, \"bilinear\",filename='ECMWF_to_1deg_xesmf_712x1440_180x360.nc')\n",
    "            # #regrid. \n",
    "            ds_out = regridder_save_weights(DSall) #this is an xarray instance now. \n",
    "            #compute from xarray in dask \n",
    "            #save:\n",
    "            print('saving... ',outfile)\n",
    "            ds_out.to_netcdf(outfile)\n",
    "        else:\n",
    "            regridder_reuse_weights = xe.Regridder(DSall, ds_out, \"bilinear\",reuse_weights=True,filename='ECMWF_to_1deg_xesmf_712x1440_180x360.nc')\n",
    "            # #regrid. \n",
    "            ds_out = regridder_reuse_weights(DSall) #this is an xarray instance now. \n",
    "            #compute from xarray in dask \n",
    "            #save:\n",
    "            print('saving... ',outfile)\n",
    "            ds_out.to_netcdf(outfile)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d280561-a4fd-4091-a1d7-605d2bb132a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client does not exist yet\n"
     ]
    }
   ],
   "source": [
    "if 'client' in locals():\n",
    "    client.shutdown()\n",
    "    print('...shutdown client...')\n",
    "else:\n",
    "    print('client does not exist yet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64121313-f238-447e-b803-0f1ebb6071f1",
   "metadata": {},
   "source": [
    "## Testing Below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfeb7c2-039c-442e-8671-bf61bcbd06bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2023b",
   "language": "python",
   "name": "npl-2023b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
