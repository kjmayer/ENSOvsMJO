{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d21e617-79f3-4efe-ba66-a8ceeea6829b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 10:02:12.166848: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-20 10:02:12.926389: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-06-20 10:02:17.427501: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /glade/u/apps/dav/opt/cuda/11.4.0/extras/CUPTI/lib64:/glade/u/apps/dav/opt/cuda/11.4.0/lib64:/glade/u/apps/dav/opt/openmpi/4.1.1/intel/19.1.1/lib:/glade/u/apps/dav/opt/ucx/1.11.0/lib:/glade/u/apps/opt/intel/2020u1/compilers_and_libraries/linux/lib/intel64:/glade/u/home/kjmayer/.conda/envs/tf2-env/lib/\n",
      "2023-06-20 10:02:17.427688: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /glade/u/apps/dav/opt/cuda/11.4.0/extras/CUPTI/lib64:/glade/u/apps/dav/opt/cuda/11.4.0/lib64:/glade/u/apps/dav/opt/openmpi/4.1.1/intel/19.1.1/lib:/glade/u/apps/dav/opt/ucx/1.11.0/lib:/glade/u/apps/opt/intel/2020u1/compilers_and_libraries/linux/lib/intel64:/glade/u/home/kjmayer/.conda/envs/tf2-env/lib/\n",
      "2023-06-20 10:02:17.427701: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import tensorflow as tf\n",
    "from trainGordon_utils import subset, build_model, fullmodel, scheduler, plot_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04a82a1-2dd5-4824-800e-17526531ae9e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Function Notes (trainGordon_utils.py):\n",
    "<code>\n",
    "# build individual models (e.g. MJO and ENSO models)\n",
    "build_model(seed, # seed to initialize weights\n",
    "            dropout_rate, # dropout rate (applied between input & first dense)\n",
    "            activity_reg, # L2 (applied to first layer)\n",
    "            hiddens, # list of nodes per each layer\n",
    "            input_shape, # input shape \n",
    "            name, # input layer name\n",
    "            biasbool=True # True = include bias term, False = no bias \n",
    "            )\n",
    "</code>\n",
    "<code>\n",
    "# linearly combine MJO and ENSO models for final prediction\n",
    "fullmodel(model1, # model 1\n",
    "          model2, # model 2\n",
    "          input1, # input into model 1 (model1)\n",
    "          input2, # input into model 2 (model2)\n",
    "          seed, # seed to initialize weights\n",
    "          )\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827b484b-db8f-4ff3-bbd8-6e134c784163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any additional functions: ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efa0ef0-8ad4-4d68-add4-6631e6c74092",
   "metadata": {},
   "source": [
    "## Load & Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8a70fc8-79c3-4c2a-a72b-aa8d364da5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_DIR = '' #input\n",
    "X2_DIR = '' #input\n",
    "Y_DIR  = '' #output\n",
    "\n",
    "X1TRAIN_FINAME = ''\n",
    "X2TRAIN_FINAME = ''\n",
    "YTRAIN_FINAME  = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d9a719-2833-474d-b724-4849bbb7df13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictors [time]\n",
    "X1train = xr.open_dataset(X1_DIR+X1TRAIN_FINAME)['VARNAME_HERE']\n",
    "\n",
    "X2trainRMM1 = xr.open_dataset(X2_DIR+X2TRAIN_FINAME)['VARNAME_HERE']\n",
    "X2trainRMM2 = xr.open_dataset(X2_DIR+X2TRAIN_FINAME)['VARNAME_HERE']\n",
    "X2train = xr.concat([X2trainRMM1,X2trainRMM2], dim = 'new_dim') # 2xtime\n",
    "\n",
    "# predictand [time]\n",
    "Ytrain = xr.open_dataset(Y_DIR+YTRAIN_FINAME)['VARNAME_HERE']\n",
    "\n",
    "# repeat for validation data\n",
    "# ----- code here -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4321cd-a62a-4ffe-8515-8b768686f7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lead\n",
    "LEAD = 7 #days\n",
    "\n",
    "# end X early, so we don't run out of Y data\n",
    "X1train = X1train[:-1*LEAD] \n",
    "X2train = X2train[:,:-1*LEAD] \n",
    "\n",
    "# shift Y to account for lead\n",
    "Ytrain = Ytrain[LEAD:]\n",
    "\n",
    "\n",
    "# repeat for validation data\n",
    "# ----- code here -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d16020-fa9d-45bd-b614-8aebdd571888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that Ytrain and X1/2train are the same size\n",
    "# ----- code here -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de9dcba-e8b4-4a05-8f9e-b7db6ac05a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: we standardize training, validation and testing using the TRAINING mean & std (or median)\n",
    "\n",
    "# standardize Xs using Xtrain\n",
    "# ----- code here -----\n",
    "\n",
    "# preprocess Ys by subtracting Ytrain median\n",
    "# ----- code here -----\n",
    "\n",
    "# turn Ys into 0s and 1s\n",
    "# ----- code here -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e592e0b-9e9c-4372-9a75-e3527fec4b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset predictand (and predictors) to same number of 0s and 1s\n",
    "    # if you subtract Ytrain median from Ytrain, you will have balanced classes, by definition\n",
    "    # therefore, you only need to subset validation (& eventually testing) data to have balanced classes\n",
    "\n",
    "n_valzero = np.shape(np.where(Yval==0)[0])[0]\n",
    "n_valone  = np.shape(np.where(Yval==1)[0])[0]\n",
    "i_valzero = np.where(Yval==0)[0]\n",
    "i_valone  = np.where(Yval==1)[0]\n",
    "\n",
    "# look into the \"subset\" function and learn how it works\n",
    "X1val, Yval, i_valnew = subset(X1val, Yval, n_valzero, n_valone, i_valzero, i_valone)\n",
    "X2val = X2.isel(time = i_valnew,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa857d82-046e-49e4-8f47-971a026effc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data from xarray to numpy (xarray takes ALOT longer to train with than numpy)\n",
    "# ----- code here -----\n",
    "# Example: X1_val = X1val.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d56a8c-eaee-44a4-9aa1-23c1c834385c",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6c6a1b4-3791-4e87-b301-5fc030accc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables:\n",
    "# As a good starting point, look at Gordon et al. (in prep) to identify what values she uses for these parameters \n",
    "# NOTE - we are inputing a value, not a map, so we likely need a much smaller network\n",
    "SEED = 1\n",
    "DROPOUT_RATE = .5\n",
    "\n",
    "MODELNAME1 = 'ENSO'\n",
    "RIDGE1 = 1\n",
    "HIDDENS1 = [100,10]\n",
    "INPUT_SHAPE1 = 1\n",
    "\n",
    "MODELNAME2 = 'MJO'\n",
    "RIDGE2 = .5\n",
    "HIDDENS2 = [50,10]\n",
    "INPUT_SHAPE2 = 1\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "N_EPOCHS = 10000\n",
    "PATIENCE = 20 # number of epochs of no \"improvement\" before training is stopped\n",
    "LR = 0.001 # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a60a80-5ae5-490a-b348-c0530a5056cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENSO MODEL\n",
    "model1, input1 = build_model(SEED,\n",
    "                             DROPOUT_RATE,\n",
    "                             RIDGE1,\n",
    "                             HIDDENS1,\n",
    "                             INPUT_SHAPE1,\n",
    "                             MODELNAME1)\n",
    "\n",
    "\n",
    "# MJO MODEL\n",
    "model2, input2 = build_model(SEED,\n",
    "                             DROPOUT_RATE,\n",
    "                             RIDGE2,\n",
    "                             HIDDENS2,\n",
    "                             INPUT_SHAPE2,\n",
    "                             MODELNAME2)   \n",
    "\n",
    "# COMBINE ENSO & MJO MODEL\n",
    "model = fullmodel(model1, model2,\n",
    "                  input1, input2,\n",
    "                  seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b932f4a8-5ab1-4671-a5e0-d4c08f0979bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ Training Hyperparameters ------\n",
    "optimizer = tf.optimizers.Adam(learning_rate = LR,)\n",
    "loss_func = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy(name=\"sparse_categorical_accuracy\", dtype=None)]                             \n",
    "\n",
    "# ------ Compile Model -----\n",
    "model.compile(optimizer = optimizer,\n",
    "              loss = loss_func,\n",
    "              metrics = metrics)\n",
    "\n",
    "# ----- Callbacks -----\n",
    "ES = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', mode = 'auto',\n",
    "                                      patience = PATIENCE, verbose = 0, restore_best_weights = True)\n",
    "LR = tf.keras.callbacks.LearningRateScheduler(scheduler,verbose=0)\n",
    "    \n",
    "\n",
    "history = model.fit({model1name:X1_train,\n",
    "                     model2name:X2_train}, \n",
    "                    Y_train, \n",
    "                    batch_size = BATCH_SIZE, \n",
    "                    epochs = N_EPOCHS, \n",
    "                    validation_data = ({model1name:X1_val,\n",
    "                                        model2name:X2_val},\n",
    "                                       Yval),  \n",
    "                    verbose = 0,\n",
    "                    callbacks=[ES,LR],\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a8cca0-de8b-4223-b26f-09721ab97480",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----- PLOT THE RESULTS -----\n",
    "plot_results(\n",
    "    history,\n",
    "    exp_info=(N_EPOCHS[:100], PATIENCE),\n",
    "    showplot=True\n",
    ") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tf2-env]",
   "language": "python",
   "name": "conda-env-.conda-tf2-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
